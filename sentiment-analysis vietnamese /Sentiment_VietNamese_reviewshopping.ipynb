{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_VietNamese_reviewshopping.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwleBYnio6YT"
      },
      "source": [
        "# **Phân loại sắc thái bình luận khách hàng** (Vietnamese sentiment analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlTfHNJ9rdFv"
      },
      "source": [
        "## Tóm tắt phương thức thực hiện bài toán"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K2zExnypXkV"
      },
      "source": [
        "1. Cuộc thi và dữ liệu\n",
        "- Cuộc thi AIVIVN: https://www.aivivn.com/contests/1\n",
        "- Dữ liệu:  file_train: train.crash, file test: test.crash, sample_submission.csv. Câu bình luận có độ dài bất kỳ được gán nhãn 0 hoặc 1, trong đó 1: bình luận tiêu cực, 0: bình luận tích cực. Tập dữ liệu huấn luyện và tập dữ liệu kiểm tra train.crash: 16086 bình luận, test.crash: 10980 bình luận.\n",
        "- Nhiệm vụ: Xác định bình luận mang ý nghĩa tiêu cực hay tích cực.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XtL1lj0p681"
      },
      "source": [
        "2. Tiền xử lý dữ liệu\n",
        "- Chuẩn hóa các ký tự bị kéo dài. VD: chiếc áo này đẹp quaaa -> chiếc áo này đẹp quá,...\n",
        "- Chuẩn hóa một số sentiment word. VD \"okie\"-> \"ok\", \"k\" ->\"không\", \"tot\"->\"tốt\",... \n",
        "- Đưa các icon về tích cực (positive) hay tiêu cực (nagative). VD: ;) -> positive, :(( ->nagative. \n",
        "- Loại bỏ các dấu câu và các ký tự nhiễu.\n",
        "- Mở rộng data bằng cách thêm các câu bình luận không dấu. Thực tế, nhiều review cũng không có dấu.\n",
        "- Mở rộng train data bằng cách thêm vào các mẫu mới là lấy từ chính 2 từ điển, từ điển positive (các từ ngữ mang yếu tố tích cực) và từ điển nagative (các từ ngữ có ý nghĩa tiêu cực)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKng3e_QqmLc"
      },
      "source": [
        "3. Lựa chọn và xây dựng mô hình\n",
        "- Các mô hình machine-learning cơ bản dùng để phân lớp dữ liệu: SVM, Navie Bayes, Logistic_Regression, Decision_Tree.\n",
        "- Các mô hình deep-learning: Mạng neuron tích chập, mạng neuron hồi tiếp, mạng LSTM.\n",
        "- Lựa chọn: Mạng neuron hồi tiếp hai chiều với kiến trúc là LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lANmHtEGrPyb"
      },
      "source": [
        "4. Quy trình thực hiện\n",
        "- Bước 1. Lấy được các trường dữ liệu: id, label, review. Tiền xử lý dữ liệu.\n",
        "\n",
        "- Bước 2. Sử dụng các công cụ để Word Embedding các từ.\n",
        "\n",
        "- Bước 3. Chuẩn hóa độ dài các câu trong dữ liệu train. Chia tập dữ liệu theo tỷ lệ 7/3.\n",
        "\n",
        "- Bước 4. Đưa vào các mô hình. Luyện mô hình.\n",
        "\n",
        "- Bước 5. Predict với dữ liệu validation_data. Predict với dữ liệu test.\n",
        "\n",
        "- Bước 6. Đánh giá độ chính xác và kết luận."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-LZSfTfrvct"
      },
      "source": [
        "## Cài đặt pytorch và google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBQ17ROZr0bS"
      },
      "source": [
        "Cài đăt pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjFe0Vlcr50G",
        "outputId": "7047f1a6-e207-4551-c37e-f940aa355e53"
      },
      "source": [
        "pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.1+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1MB 1.3MB/s eta 0:14:35tcmalloc: large alloc 1147494400 bytes == 0x55c22d9cc000 @  0x7f6a92537615 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c487f0 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4d493e1 0x55c1f4ca96a9 0x55c1f4c14cc4 0x55c1f4bd5559 0x55c1f4c494f8 0x55c1f4bd630a 0x55c1f4c443b5 0x55c1f4c437ad 0x55c1f4bd63ea 0x55c1f4c443b5 0x55c1f4bd630a 0x55c1f4c443b5\n",
            "\u001b[K     |█████████████████               | 1055.7MB 1.2MB/s eta 0:12:31tcmalloc: large alloc 1434370048 bytes == 0x55c272022000 @  0x7f6a92537615 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c487f0 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4d493e1 0x55c1f4ca96a9 0x55c1f4c14cc4 0x55c1f4bd5559 0x55c1f4c494f8 0x55c1f4bd630a 0x55c1f4c443b5 0x55c1f4c437ad 0x55c1f4bd63ea 0x55c1f4c443b5 0x55c1f4bd630a 0x55c1f4c443b5\n",
            "\u001b[K     |█████████████████████▋          | 1336.2MB 1.5MB/s eta 0:07:21tcmalloc: large alloc 1792966656 bytes == 0x55c1f6e54000 @  0x7f6a92537615 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c487f0 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4d493e1 0x55c1f4ca96a9 0x55c1f4c14cc4 0x55c1f4bd5559 0x55c1f4c494f8 0x55c1f4bd630a 0x55c1f4c443b5 0x55c1f4c437ad 0x55c1f4bd63ea 0x55c1f4c443b5 0x55c1f4bd630a 0x55c1f4c443b5\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1MB 1.3MB/s eta 0:03:39tcmalloc: large alloc 2241208320 bytes == 0x55c261c3c000 @  0x7f6a92537615 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c487f0 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4d493e1 0x55c1f4ca96a9 0x55c1f4c14cc4 0x55c1f4bd5559 0x55c1f4c494f8 0x55c1f4bd630a 0x55c1f4c443b5 0x55c1f4c437ad 0x55c1f4bd63ea 0x55c1f4c443b5 0x55c1f4bd630a 0x55c1f4c443b5\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 1.2MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0x55c2e759e000 @  0x7f6a925361e7 0x55c1f4c07f37 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4bd630a 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4c434ae\n",
            "tcmalloc: large alloc 2477727744 bytes == 0x55c3d1cbe000 @  0x7f6a92537615 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4bd630a 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4c434ae 0x55c1f4bd6a81\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 5.3kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6MB 235kB/s \n",
            "\u001b[?25hCollecting torchaudio===0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhKMRkgVtkwB"
      },
      "source": [
        "Kết nối google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-OMoMN2tj3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ac581d-094a-4300-9637-9d9a0e3962a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PxAHKiAuD0w"
      },
      "source": [
        "Cài đặt thư viên"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhQtlXJzuF95"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from nltk.corpus import stopwords \n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_P1V2ZeuSbi"
      },
      "source": [
        "## Hiển thị và tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiLjOdsc03Rk",
        "outputId": "cbdd2764-7b05-41cb-a7f9-a41f799f15ff"
      },
      "source": [
        "pip install pyvi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyvi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/e1/0e5bc6b5e3327b9385d6e0f1b0a7c0404f28b74eb6db59a778515b30fd9c/pyvi-0.1-py2.py3-none-any.whl (8.5MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5MB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.0.1)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 42.8MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.7 pyvi-0.1 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo50D3Q_vw15"
      },
      "source": [
        "import pandas as pd\n",
        "from pyvi import ViTokenizer\n",
        "import re\n",
        "import string\n",
        "import codecs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39UwyuNsvmtp"
      },
      "source": [
        "Xây dựng các từ điển tích cực, từ điển tiêu cực"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeIlDQVLuXau"
      },
      "source": [
        "path = \"/content/gdrive/MyDrive/sentiment_vietnamese/sentiment_dicts\"\n",
        "path_nag = path + '/nag.txt'\n",
        "path_pos = path + '/pos.txt'\n",
        "path_not = path + '/not.txt'\n",
        "VN_CHARS_LOWER = u'ạảãàáâậầấẩẫăắằặẳẵóòọõỏôộổỗồốơờớợởỡéèẻẹẽêếềệểễúùụủũưựữửừứíìịỉĩýỳỷỵỹđð'\n",
        "VN_CHARS_UPPER = u'ẠẢÃÀÁÂẬẦẤẨẪĂẮẰẶẲẴÓÒỌÕỎÔỘỔỖỒỐƠỜỚỢỞỠÉÈẺẸẼÊẾỀỆỂỄÚÙỤỦŨƯỰỮỬỪỨÍÌỊỈĨÝỲỶỴỸÐĐ'\n",
        "VN_CHARS = VN_CHARS_LOWER + VN_CHARS_UPPER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqIocZZYwyLH"
      },
      "source": [
        "def diction_nag_pos_not():\n",
        "    with codecs.open(path_nag, 'r', encoding='UTF-8') as f:\n",
        "        nag = f.readlines()\n",
        "    nag_list = [n.replace('\\n', '') for n in nag]\n",
        "\n",
        "    with codecs.open(path_pos, 'r', encoding='UTF-8') as f:\n",
        "        pos = f.readlines()\n",
        "    pos_list = [n.replace('\\n', '') for n in pos]\n",
        "    with codecs.open(path_not, 'r', encoding='UTF-8') as f:\n",
        "        not_ = f.readlines()\n",
        "    not_list = [n.replace('\\n', '') for n in not_]\n",
        "    return nag_list, pos_list, not_list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyAeR42Lw2dr"
      },
      "source": [
        "nag_list, pos_list, not_list = diction_nag_pos_not()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41ZppTlow6sX",
        "outputId": "5d575786-a197-48dc-b113-743a7898e12d"
      },
      "source": [
        "print(nag_list[0:5])\n",
        "print(pos_list[0:5])\n",
        "print(not_list) # Tập các từ phủ định"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bất lợi', 'chán', 'chật hẹchật', 'chật', 'tức giận']\n",
            "['ưng ý', 'ưng', 'kỹ', 'được', 'ô kê']\n",
            "['không', 'vô', 'chẳng', 'đếch', 'chưa', 'đéo', 'kém', 'nỏ', 'not']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiUcFpmnxOfH"
      },
      "source": [
        "Hàm bỏ dấu cho text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8emTBn0xXPo"
      },
      "source": [
        "def no_marks(s):\n",
        "    __INTAB = [ch for ch in VN_CHARS]\n",
        "    __OUTTAB = \"a\" * 17 + \"o\" * 17 + \"e\" * 11 + \"u\" * 11 + \"i\" * 5 + \"y\" * 5 + \"d\" * 2\n",
        "    __OUTTAB += \"A\" * 17 + \"O\" * 17 + \"E\" * 11 + \"U\" * 11 + \"I\" * 5 + \"Y\" * 5 + \"D\" * 2\n",
        "    __r = re.compile(\"|\".join(__INTAB))\n",
        "    __replaces_dict = dict(zip(__INTAB, __OUTTAB))\n",
        "    result = __r.sub(lambda m: __replaces_dict[m.group(0)], s)\n",
        "    return result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBg11DEfxeZ4",
        "outputId": "54f3d850-5ffa-4777-8795-4b9e659c5084"
      },
      "source": [
        "s = \"sản phẩm này rất đẹp\"\n",
        "print(no_marks(s))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "san pham nay rat dep\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot72fWe6xpwX"
      },
      "source": [
        "### Hàm chuẩn hoá: \n",
        "- loại bỏ các ký tự kéo dài\n",
        "- chuyển text thành chữ thường\n",
        "- thêm feauture cho các sentiment work: \"Áo này đẹp\" chuyển thành \"Áo này đẹp positive\".  \n",
        "- loại bỏ chấm câu.\n",
        "- chuẩn hoá các từ tiếng Anh, các icon, các từ viết tắt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbrwOmj-ycka"
      },
      "source": [
        "def normalize_text(text):\n",
        "    # Remove các ký tự kéo dài: vd: đẹppppppp\n",
        "    text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Chuyển thành chữ thường\n",
        "    text = text.lower()\n",
        "\n",
        "    # Chuẩn hóa tiếng Việt, xử lý emoj, chuẩn hóa tiếng Anh, thuật ngữ\n",
        "    replace_list = {\n",
        "        'òa': 'oà', 'óa': 'oá', 'ỏa': 'oả', 'õa': 'oã', 'ọa': 'oạ', 'òe': 'oè', 'óe': 'oé', 'ỏe': 'oẻ',\n",
        "        'õe': 'oẽ', 'ọe': 'oẹ', 'ùy': 'uỳ', 'úy': 'uý', 'ủy': 'uỷ', 'ũy': 'uỹ', 'ụy': 'uỵ', 'uả': 'ủa',\n",
        "        'ả': 'ả', 'ố': 'ố', 'u´': 'ố', 'ỗ': 'ỗ', 'ồ': 'ồ', 'ổ': 'ổ', 'ấ': 'ấ', 'ẫ': 'ẫ', 'ẩ': 'ẩ',\n",
        "        'ầ': 'ầ', 'ỏ': 'ỏ', 'ề': 'ề', 'ễ': 'ễ', 'ắ': 'ắ', 'ủ': 'ủ', 'ế': 'ế', 'ở': 'ở', 'ỉ': 'ỉ',\n",
        "        'ẻ': 'ẻ', 'àk': u' à ', 'aˋ': 'à', 'iˋ': 'ì', 'ă´': 'ắ', 'ử': 'ử', 'e˜': 'ẽ', 'y˜': 'ỹ', 'a´': 'á',\n",
        "        # Quy các icon về 2 loại emoj: Tích cực hoặc tiêu cực\n",
        "        \"👹\": \"nagative\", \"👻\": \"positive\", \"💃\": \"positive\", '🤙': ' positive ', '👍': ' positive ',\n",
        "        \"💄\": \"positive\", \"💎\": \"positive\", \"💩\": \"positive\", \"😕\": \"nagative\", \"😱\": \"nagative\", \"😸\": \"positive\",\n",
        "        \"😾\": \"nagative\", \"🚫\": \"nagative\", \"🤬\": \"nagative\", \"🧚\": \"positive\", \"🧡\": \"positive\", '🐶': ' positive ',\n",
        "        '👎': ' nagative ', '😣': ' nagative ', '✨': ' positive ', '❣': ' positive ', '☀': ' positive ',\n",
        "        '♥': ' positive ', '🤩': ' positive ', 'like': ' positive ', '💌': ' positive ',\n",
        "        '🤣': ' positive ', '🖤': ' positive ', '🤤': ' positive ', ':(': ' nagative ', '😢': ' nagative ',\n",
        "        '❤': ' positive ', '😍': ' positive ', '😘': ' positive ', '😪': ' nagative ', '😊': ' positive ',\n",
        "        '?': ' ? ', '😁': ' positive ', '💖': ' positive ', '😟': ' nagative ', '😭': ' nagative ',\n",
        "        '💯': ' positive ', '💗': ' positive ', '♡': ' positive ', '💜': ' positive ', '🤗': ' positive ',\n",
        "        '^^': ' positive ', '😨': ' nagative ', '☺': ' positive ', '💋': ' positive ', '👌': ' positive ',\n",
        "        '😖': ' nagative ', '😀': ' positive ', ':((': ' nagative ', '😡': ' nagative ', '😠': ' nagative ',\n",
        "        '😒': ' nagative ', '🙂': ' positive ', '😏': ' nagative ', '😝': ' positive ', '😄': ' positive ',\n",
        "        '😙': ' positive ', '😤': ' nagative ', '😎': ' positive ', '😆': ' positive ', '💚': ' positive ',\n",
        "        '✌': ' positive ', '💕': ' positive ', '😞': ' nagative ', '😓': ' nagative ', '️🆗️': ' positive ',\n",
        "        '😉': ' positive ', '😂': ' positive ', ':v': '  positive ', '=))': '  positive ', '😋': ' positive ',\n",
        "        '💓': ' positive ', '😐': ' nagative ', ':3': ' positive ', '😫': ' nagative ', '😥': ' nagative ',\n",
        "        '😃': ' positive ', '😬': ' 😬 ', '😌': ' 😌 ', '💛': ' positive ', '🤝': ' positive ', '🎈': ' positive ',\n",
        "        '😗': ' positive ', '🤔': ' nagative ', '😑': ' nagative ', '🔥': ' nagative ', '🙏': ' nagative ',\n",
        "        '🆗': ' positive ', '😻': ' positive ', '💙': ' positive ', '💟': ' positive ',\n",
        "        '😚': ' positive ', '❌': ' nagative ', '👏': ' positive ', ';)': ' positive ', '<3': ' positive ',\n",
        "        '🌝': ' positive ', '🌷': ' positive ', '🌸': ' positive ', '🌺': ' positive ',\n",
        "        '🌼': ' positive ', '🍓': ' positive ', '🐅': ' positive ', '🐾': ' positive ', '👉': ' positive ',\n",
        "        '💐': ' positive ', '💞': ' positive ', '💥': ' positive ', '💪': ' positive ',\n",
        "        '💰': ' positive ', '😇': ' positive ', '😛': ' positive ', '😜': ' positive ',\n",
        "        '🙃': ' positive ', '🤑': ' positive ', '🤪': ' positive ', '☹': ' nagative ', '💀': ' nagative ',\n",
        "        '😔': ' nagative ', '😧': ' nagative ', '😩': ' nagative ', '😰': ' nagative ', '😳': ' nagative ',\n",
        "        '😵': ' nagative ', '😶': ' nagative ', '🙁': ' nagative ',\n",
        "        # Chuẩn hóa 1 số sentiment words/English words\n",
        "        ':))': '  positive ', ':)': ' positive ', 'ô kêi': ' ok ', 'okie': ' ok ', ' o kê ': ' ok ',\n",
        "        'okey': ' ok ', 'ôkê': ' ok ', 'oki': ' ok ', ' oke ': ' ok ', ' okay': ' ok ', 'okê': ' ok ',\n",
        "        ' tks ': u' cám ơn ', 'thks': u' cám ơn ', 'thanks': u' cám ơn ', 'ths': u' cám ơn ', 'thank': u' cám ơn ',\n",
        "        '⭐': 'star ', '*': 'star ', '🌟': 'star ', '🎉': u' positive ',\n",
        "        'kg ': u' không ', 'not': u' không ', u' kg ': u' không ', '\"k ': u' không ', ' kh ': u' không ',\n",
        "        'kô': u' không ', 'hok': u' không ', ' kp ': u' không phải ', u' kô ': u' không ', '\"ko ': u' không ',\n",
        "        u' ko ': u' không ', u' k ': u' không ', 'khong': u' không ', u' hok ': u' không ',\n",
        "        'he he': ' positive ', 'hehe': ' positive ', 'hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',\n",
        "        ' lol ': ' nagative ', ' cc ': ' nagative ', 'cute': u' dễ thương ', 'huhu': ' nagative ', ' vs ': u' với ',\n",
        "        'wa': ' quá ', 'wá': u' quá', 'j': u' gì ', '“': ' ',\n",
        "        ' sz ': u' cỡ ', 'size': u' cỡ ', u' đx ': u' được ', 'dk': u' được ', 'dc': u' được ', 'đk': u' được ',\n",
        "        'đc': u' được ', 'authentic': u' chuẩn chính hãng ', u' aut ': u' chuẩn chính hãng ',\n",
        "        u' auth ': u' chuẩn chính hãng ', 'thick': u' positive ', 'store': u' cửa hàng ',\n",
        "        'shop': u' cửa hàng ', 'sp': u' sản phẩm ', 'gud': u' tốt ', 'god': u' tốt ', 'wel done': ' tốt ',\n",
        "        'good': u' tốt ', 'gút': u' tốt ',\n",
        "        'sấu': u' xấu ', 'gut': u' tốt ', u' tot ': u' tốt ', u' nice ': u' tốt ', 'perfect': 'rất tốt',\n",
        "        'bt': u' bình thường ',\n",
        "        'time': u' thời gian ', 'qá': u' quá ', u' ship ': u' giao hàng ', u' m ': u' mình ', u' mik ': u' mình ',\n",
        "        'ể': 'ể', 'product': 'sản phẩm', 'quality': 'chất lượng', 'chat': ' chất ', 'excelent': 'hoàn hảo',\n",
        "        'bad': 'tệ', 'fresh': ' tươi ', 'sad': ' tệ ',\n",
        "        'date': u' hạn sử dụng ', 'hsd': u' hạn sử dụng ', 'quickly': u' nhanh ', 'quick': u' nhanh ',\n",
        "        'fast': u' nhanh ', 'delivery': u' giao hàng ', u' síp ': u' giao hàng ',\n",
        "        'beautiful': u' đẹp tuyệt vời ', u' tl ': u' trả lời ', u' r ': u' rồi ', u' shopE ': u' cửa hàng ',\n",
        "        u' order ': u' đặt hàng ',\n",
        "        'chất lg': u' chất lượng ', u' sd ': u' sử dụng ', u' dt ': u' điện thoại ', u' nt ': u' nhắn tin ',\n",
        "        u' tl ': u' trả lời ', u' sài ': u' xài ', u'bjo': u' bao giờ ',\n",
        "        'thik': u' thích ', u' sop ': u' cửa hàng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rất ',\n",
        "        u'quả ng ': u' quảng  ',\n",
        "        'dep': u' đẹp ', u' xau ': u' xấu ', 'delicious': u' ngon ', u'hàg': u' hàng ', u'qủa': u' quả ',\n",
        "        'iu': u' yêu ', 'fake': u' giả mạo ', 'trl': 'trả lời', '><': u' positive ',\n",
        "        ' por ': u' tệ ', ' poor ': u' tệ ', 'ib': u' nhắn tin ', 'rep': u' trả lời ', u'fback': ' feedback ',\n",
        "        'fedback': ' feedback ',\n",
        "        # dưới 3* quy về 1*, trên 3* quy về 5*\n",
        "        '6 sao': ' 5star ', '6 star': ' 5star ', '5star': ' 5star ', '5 sao': ' 5star ', '5sao': ' 5star ',\n",
        "        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ', '2 sao': ' 1star ', '2sao': ' 1star ',\n",
        "        '2 starstar': ' 1star ', '1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ', }\n",
        "\n",
        "    for k, v in replace_list.items():\n",
        "        text = text.replace(k, v)\n",
        "\n",
        "    # chuyen punctuation thành space\n",
        "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    text = ViTokenizer.tokenize(text)\n",
        "    texts = text.split()\n",
        "    len_text = len(texts)\n",
        "    nag_list, pos_list, not_list = diction_nag_pos_not()\n",
        "    texts = [t.replace('_', ' ') for t in texts]\n",
        "    for i in range(len_text):\n",
        "        cp_text = texts[i]\n",
        "        if cp_text in not_list:  # Xử lý vấn đề phủ định (VD: áo này chẳng đẹp--> áo này notpos)\n",
        "            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1\n",
        "\n",
        "            for j in range(numb_word):\n",
        "                if texts[i + j + 1] in pos_list:\n",
        "                    texts[i] = 'notpos'\n",
        "                    texts[i + j + 1] = ''\n",
        "\n",
        "                if texts[i + j + 1] in nag_list:\n",
        "                    texts[i] = 'notnag'\n",
        "                    texts[i + j + 1] = ''\n",
        "        else:  # Thêm feature cho những sentiment words (áo này đẹp--> áo này đẹp positive)\n",
        "            if cp_text in pos_list:\n",
        "                texts.append('positive')\n",
        "            elif cp_text in nag_list:\n",
        "                texts.append('nagative')\n",
        "\n",
        "    text = u' '.join(texts)\n",
        "\n",
        "    # remove nốt những ký tự thừa thãi\n",
        "    text = text.replace(u'\"', u' ')\n",
        "    text = text.replace(u'️', u'')\n",
        "    text = text.replace('🏻', '')\n",
        "    return text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAjYn-6ayv00"
      },
      "source": [
        "### Hiển thị và phân tích dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJOqx_HLy2CG"
      },
      "source": [
        "class DataSource(object):\n",
        "    def _load_raw_data(self, filename, is_train=True):\n",
        "        a = []\n",
        "        b = []\n",
        "        regex = 'train_'\n",
        "        if not is_train:\n",
        "            regex = 'test_'\n",
        "        with open(filename, 'r', encoding='utf8') as file:\n",
        "            for line in file:\n",
        "                if regex in line:\n",
        "                    b.append(a)\n",
        "                    a = [line]\n",
        "                elif line != '\\n':\n",
        "                    a.append(line)\n",
        "        b.append(a)\n",
        "        return b[1:]\n",
        "\n",
        "    def _create_row(self, sample, is_train=True):\n",
        "        d = {}\n",
        "        d['id'] = sample[0].replace('\\n', '')\n",
        "        review = \"\"\n",
        "        if is_train:\n",
        "            for clause in sample[1:-1]:\n",
        "                review += clause.replace('\\n', '').strip()\n",
        "            d['label'] = int(sample[-1].replace('\\n', ''))\n",
        "        else:\n",
        "            for clause in sample[1:]:\n",
        "                review += clause.replace('\\n', '').strip()\n",
        "        d['review'] = review\n",
        "        return d\n",
        "\n",
        "    def load_data(self, filename, is_train=True):\n",
        "\n",
        "        raw_data = self._load_raw_data(filename, is_train)\n",
        "        lst = []\n",
        "\n",
        "        for row in raw_data:\n",
        "            lst.append(self._create_row(row, is_train))\n",
        "\n",
        "        return lst\n",
        "\n",
        "    def transform_to_dataset(self, x_set, y_set):\n",
        "        X, y = [], []\n",
        "        for document, topic in zip(list(x_set), list(y_set)):\n",
        "            document = normalize_text(document)\n",
        "            X.append(document.strip())\n",
        "            y.append(topic)\n",
        "            # Augmentation bằng cách remove dấu tiếng Việt\n",
        "            X.append(no_marks(document))\n",
        "            y.append(topic)\n",
        "        return X, y"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIbCfi33zE6p"
      },
      "source": [
        "def return_data():\n",
        "    ds = DataSource()\n",
        "    train_data = pd.DataFrame(ds.load_data(\"/content/gdrive/MyDrive/sentiment_vietnamese/train.crash\"))\n",
        "    new_data = []\n",
        "    '''\n",
        "    # Thêm mẫu bằng cách lấy trong từ điển Sentiment (nag/pos)\n",
        "    nag_list, pos_list, not_list = diction_nag_pos_not()\n",
        "    for index, row in enumerate(pos_list):\n",
        "        new_data.append(['pos' + str(index), '0', row])\n",
        "    for index, row in enumerate(nag_list):\n",
        "        new_data.append(['nag' + str(index), '1', row])\n",
        "    '''\n",
        "    new_data = pd.DataFrame(new_data, columns=list(['id', 'label', 'review']))\n",
        "    train_data = train_data.append(new_data, ignore_index=True)\n",
        "    test_data = pd.DataFrame(ds.load_data('/content/gdrive/MyDrive/sentiment_vietnamese/test.crash', is_train=False))\n",
        "    return train_data, test_data"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyXNqgXYzUBE"
      },
      "source": [
        "train_data, test_data = return_data()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkfqD8M_z5Au"
      },
      "source": [
        "Dữ liệu huấn luyện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zzoxzfX9zzLV",
        "outputId": "a6d5b613-555a-4c09-d1ef-f1562fba7c89"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_000000</td>\n",
              "      <td>0</td>\n",
              "      <td>\"Dung dc sp tot cam onshop Đóng gói sản phẩm r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_000001</td>\n",
              "      <td>0</td>\n",
              "      <td>\" Chất lượng sản phẩm tuyệt vời . Son mịn nhưn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_000002</td>\n",
              "      <td>0</td>\n",
              "      <td>\" Chất lượng sản phẩm tuyệt vời nhưng k có hộp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_000003</td>\n",
              "      <td>1</td>\n",
              "      <td>\":(( Mình hơi thất vọng 1 chút vì mình đã kỳ v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_000004</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Lần trước mình mua áo gió màu hồng rất ok mà ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16082</th>\n",
              "      <td>train_016082</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Chẳng biết là Shop có biết đọc hay không mua ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16083</th>\n",
              "      <td>train_016083</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Cuốn này mỏng. Đọc một buổi sáng là hết. Thú ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16084</th>\n",
              "      <td>train_016084</td>\n",
              "      <td>0</td>\n",
              "      <td>\"Mang êm chân. Đẹp \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16085</th>\n",
              "      <td>train_016085</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Tôi đã nhận đc hàng.Sau đây là vài lời muốn n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16086</th>\n",
              "      <td>train_016086</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Hình vậy mà túi xấu qá kém chất lg qá\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16087 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id label                                             review\n",
              "0      train_000000     0  \"Dung dc sp tot cam onshop Đóng gói sản phẩm r...\n",
              "1      train_000001     0  \" Chất lượng sản phẩm tuyệt vời . Son mịn nhưn...\n",
              "2      train_000002     0  \" Chất lượng sản phẩm tuyệt vời nhưng k có hộp...\n",
              "3      train_000003     1  \":(( Mình hơi thất vọng 1 chút vì mình đã kỳ v...\n",
              "4      train_000004     1  \"Lần trước mình mua áo gió màu hồng rất ok mà ...\n",
              "...             ...   ...                                                ...\n",
              "16082  train_016082     1  \"Chẳng biết là Shop có biết đọc hay không mua ...\n",
              "16083  train_016083     1  \"Cuốn này mỏng. Đọc một buổi sáng là hết. Thú ...\n",
              "16084  train_016084     0                               \"Mang êm chân. Đẹp \"\n",
              "16085  train_016085     1  \"Tôi đã nhận đc hàng.Sau đây là vài lời muốn n...\n",
              "16086  train_016086     1            \"Hình vậy mà túi xấu qá kém chất lg qá\"\n",
              "\n",
              "[16087 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6dSmpdsz8Rv"
      },
      "source": [
        "Dữ liệu kiểm tra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "syUXQMipz-zq",
        "outputId": "9f6f5269-5433-486a-c3a2-53d331924509"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_000000</td>\n",
              "      <td>\"Chưa dùng thử nên chưa biết\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_000001</td>\n",
              "      <td>\" Không đáng tiềnVì ngay đợt sale nên mới mua ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_000002</td>\n",
              "      <td>\"Cám ơn shop. Đóng gói sản phẩm rất đẹp và chắ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_000003</td>\n",
              "      <td>\"Vải đẹp.phom oki luôn.quá ưng\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_000004</td>\n",
              "      <td>\"Chuẩn hàng đóng gói đẹp\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10976</th>\n",
              "      <td>test_010976</td>\n",
              "      <td>\" Thời gian giao hàng rất nhanh.ngon.mà cay qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10977</th>\n",
              "      <td>test_010977</td>\n",
              "      <td>\"Sản phẩm hơi cũ\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10978</th>\n",
              "      <td>test_010978</td>\n",
              "      <td>\"Sản phẩm chắc chắn nhưng k bóng bằng trong hình\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10979</th>\n",
              "      <td>test_010979</td>\n",
              "      <td>\" Chất lượng sản phẩm tuyệt vời có mùi thơm rấ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10980</th>\n",
              "      <td>test_010980</td>\n",
              "      <td>\"như quảng cáo. sim rất tốt\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10981 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                id                                             review\n",
              "0      test_000000                      \"Chưa dùng thử nên chưa biết\"\n",
              "1      test_000001  \" Không đáng tiềnVì ngay đợt sale nên mới mua ...\n",
              "2      test_000002  \"Cám ơn shop. Đóng gói sản phẩm rất đẹp và chắ...\n",
              "3      test_000003                    \"Vải đẹp.phom oki luôn.quá ưng\"\n",
              "4      test_000004                          \"Chuẩn hàng đóng gói đẹp\"\n",
              "...            ...                                                ...\n",
              "10976  test_010976  \" Thời gian giao hàng rất nhanh.ngon.mà cay qu...\n",
              "10977  test_010977                                  \"Sản phẩm hơi cũ\"\n",
              "10978  test_010978  \"Sản phẩm chắc chắn nhưng k bóng bằng trong hình\"\n",
              "10979  test_010979  \" Chất lượng sản phẩm tuyệt vời có mùi thơm rấ...\n",
              "10980  test_010980                       \"như quảng cáo. sim rất tốt\"\n",
              "\n",
              "[10981 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E-ZdJoH1A27"
      },
      "source": [
        "Khởi tạo class DataSource tiền xử lý tập dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knB9miuG0Xqm"
      },
      "source": [
        "ds = DataSource()\n",
        "X_train, y_train = ds.transform_to_dataset(train_data.review, train_data.label)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVUR-VAI1QoB",
        "outputId": "8f51a0ba-fa20-41a5-8b40-7c3ea6fcea67"
      },
      "source": [
        "print(\"Tập dữ liệu: \", X_train[0:5])\n",
        "print(\"Kích thước tập dữ liệu:\", len(X_train))\n",
        "print(\"Tập nhãn:\", y_train[0:5])\n",
        "print(\"Kích thước tập nhãn:\", len(y_train))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tập dữ liệu:  ['dung được sản phẩm tốt cam on cửa hàng đóng gói sản phẩm rất đẹp và chắc chắn chất lượng sản phẩm tuyệt vời positive positive positive positive positive positive', 'dung duoc san pham tot cam on cua hang dong goi san pham rat dep va chac chan chat luong san pham tuyet voi positive positive positive positive positive positive', 'chất lượng sản phẩm tuyệt vời son mịn nhưng khi đánh lên không như màu trên ảnh positive positive positive', 'chat luong san pham tuyet voi son min nhung khi danh len khong nhu mau tren anh positive positive positive', 'chất lượng sản phẩm tuyệt vời nhưng không có hộp không có dây giày đen không có tất positive positive']\n",
            "Kích thước tập dữ liệu: 32174\n",
            "Tập nhãn: [0, 0, 0, 0, 0]\n",
            "Kích thước tập nhãn: 32174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rkUD58a16P2"
      },
      "source": [
        "Chia tập dữ liệu ban đầu thành 2 phần X_train, y_train và X_test, y_test theo tỉ lệ 3:1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chd-Y0Nm2GaH",
        "outputId": "177829fb-bae8-465b-8bf8-2057e7aa7e31"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3,\n",
        "                                                        random_state=42)\n",
        "x_train, x_test = np.asarray(x_train), np.asarray(x_test)\n",
        "y_train, y_test = np.asarray(y_train), np.asarray(y_test)\n",
        "print(\"Số lượng dữ liệu huấn luyện {}\".format(x_train.shape))\n",
        "print(\"Số lượng dữ liệu kiểm tra {}\".format(x_test.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Số lượng dữ liệu huấn luyện (22521,)\n",
            "Số lượng dữ liệu kiểm tra (9653,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbp42E2P3w6R"
      },
      "source": [
        "Hiển thị số lượng nhãn tích cực nhãn 0 và số lượng nhãn tiêu cực nhãn 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOs3n8723xyU",
        "outputId": "d9f813fb-259e-47c1-e3fb-c081e12ca7f2"
      },
      "source": [
        "np.unique(y_train, return_counts= True)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([13004,  9517]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zSVkyO5432mY",
        "outputId": "eb798e60-7078-4fb8-cd82-90ca2977191c"
      },
      "source": [
        "dd = pd.Series(y_train).value_counts()\n",
        "sns.barplot(x=np.array(['positive','negative']),y=dd.values)\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cilddjmX4dGS"
      },
      "source": [
        "Tokenize dữ liệu: đưa ra tập từ điển, idex của một câu trong tập dữ liệu huấn luyện và tập dữ liệu kiểm tra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWhyFd7D4DPD"
      },
      "source": [
        "def preprocess_string(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with no space\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # replace digits with no space\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRDQa1Hk5HDD",
        "outputId": "52c9a11c-def4-4128-90af-d760b5d9837f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop = set(stopwords.words('english'))\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7-YgMuu5K1C"
      },
      "source": [
        "def tockenize(x_train,y_train,x_val,y_val):\n",
        "    word_list = []\n",
        "\n",
        "    stop_words = stop\n",
        "    for sent in x_train:\n",
        "        for word in sent.lower().split():\n",
        "            word = preprocess_string(word)\n",
        "            if word not in stop_words and word != '':\n",
        "                word_list.append(word)\n",
        "  \n",
        "    corpus = Counter(word_list)\n",
        "    # sorting on the basis of most common words\n",
        "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
        "    # creating a dict\n",
        "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
        "    \n",
        "    # tockenize\n",
        "    final_list_train,final_list_test = [],[]\n",
        "    for sent in x_train:\n",
        "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
        "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
        "    for sent in x_val:\n",
        "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
        "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
        "            \n",
        "    # encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n",
        "    # encoded_test = [1 if label =='positive' else 0 for label in y_val] \n",
        "    encoded_train = y_train\n",
        "    encoded_test = y_val\n",
        "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juXqqT6V5PdX",
        "outputId": "33c01a51-33aa-4226-fdd4-50642f7397f7"
      },
      "source": [
        "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IpMMIbWe6dP",
        "outputId": "ae62559c-7283-43e1-e631-5bb88db579f8"
      },
      "source": [
        "print(x_train)\n",
        "print(y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[list([157, 427, 116, 86, 386, 84, 220, 157, 116, 86, 230, 12, 3, 2])\n",
            " list([170, 24, 27, 572, 73, 31, 7, 4, 20, 191, 174, 50, 53, 134, 325, 563, 179, 168, 1, 1])\n",
            " list([81, 16, 536, 58, 318, 282, 40, 520, 12, 3, 86, 115, 438, 40, 12, 3, 15, 121, 139, 193, 446, 39, 2, 2])\n",
            " ...\n",
            " list([7, 4, 20, 513, 28, 665, 4, 497, 497, 190, 195, 558, 314, 188, 54, 124, 122, 64, 150, 134, 77, 671, 252, 118, 422, 72, 134, 325, 563, 16, 96, 13, 4, 88, 84, 1])\n",
            " list([12, 3, 66, 31, 116, 120, 89, 41, 99, 212, 43, 7, 89, 41, 86, 89, 67, 114, 87, 107, 113, 15, 121, 139, 66, 153, 423, 114, 12, 12, 3, 189, 1])\n",
            " list([7, 18, 374, 94, 4])]\n",
            "[0 0 1 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxGrPcvJ5Yv0"
      },
      "source": [
        "## Mã hoá dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ky_QyDd5c9y",
        "outputId": "34ead871-ae49-48f9-9f52-8f7f38be755f"
      },
      "source": [
        "print(len(x_train))\n",
        "print(\"Hiển thị dữ liệu huấn luyện sau khi mã hoá:\", x_train[0:5])\n",
        "print(len(y_train))\n",
        "y_train\n",
        "print(vocab)\n",
        "print(\"Kích thước của từ điển:\",len(vocab))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22521\n",
            "Hiển thị dữ liệu huấn luyện sau khi mã hoá: [list([157, 427, 116, 86, 386, 84, 220, 157, 116, 86, 230, 12, 3, 2])\n",
            " list([170, 24, 27, 572, 73, 31, 7, 4, 20, 191, 174, 50, 53, 134, 325, 563, 179, 168, 1, 1])\n",
            " list([81, 16, 536, 58, 318, 282, 40, 520, 12, 3, 86, 115, 438, 40, 12, 3, 15, 121, 139, 193, 446, 39, 2, 2])\n",
            " list([263, 803, 46, 321, 71, 14, 31, 63, 500, 63, 803, 972, 131, 573, 334, 487, 49, 343, 352, 487, 803, 134, 574, 630, 295, 174, 487, 122, 18, 487, 803, 14, 105, 505, 209, 192, 283, 11, 10, 102, 38, 94, 582, 91, 487, 172, 209, 192, 2, 2, 2, 2])\n",
            " list([38, 16, 36, 90, 655, 527, 91, 439, 4, 14, 191, 140, 19, 22, 11, 10, 6, 118, 13, 4, 79, 74, 6, 2, 2, 1])]\n",
            "22521\n",
            "{'positive': 1, 'nagative': 2, 'hang': 3, 'hàng': 4, 'rat': 5, 'rất': 6, 'giao': 7, 'pham': 8, 'san': 9, 'phẩm': 10, 'sản': 11, 'cua': 12, 'cửa': 13, 'không': 14, 'khong': 15, 'mua': 16, 'chat': 17, 'notpos': 18, 'chất': 19, 'nhanh': 20, 'luong': 21, 'lượng': 22, 'dep': 23, 'đẹp': 24, 'co': 25, 'va': 26, 'và': 27, 'goi': 28, 'dong': 29, 'voi': 30, 'gian': 31, 'cho': 32, 'gói': 33, 'dung': 34, 'minh': 35, 'có': 36, 'đóng': 37, 'mình': 38, 'qua': 39, 'nhung': 40, 'la': 41, 'chan': 42, 'thi': 43, 'tuyệt': 44, 'tuyet': 45, 'chắc': 46, 'chac': 47, 'tien': 48, 'thì': 49, 'là': 50, 'tot': 51, 'duoc': 52, 'tốt': 53, 'nhưng': 54, 'vời': 55, 'dang': 56, 'tiền': 57, 'da': 58, 'thoi': 59, 'nhu': 60, 'chắn': 61, 'được': 62, 'mà': 63, 'ok': 64, 'bi': 65, 'lam': 66, 'nhan': 67, 'khi': 68, 'mau': 69, 'đáng': 70, 'quá': 71, 'ra': 72, 'thời': 73, 'vụ': 74, 'cung': 75, 'kem': 76, 'như': 77, 'nay': 78, 'phục': 79, 'vu': 80, 'moi': 81, 'phuc': 82, 'gia': 83, 'lai': 84, 'con': 85, 'de': 86, 'hoi': 87, 'trong': 88, 'ban': 89, 'bị': 90, 'lại': 91, 'nen': 92, 'thay': 93, 'đã': 94, 'ho': 95, 'của': 96, 'với': 97, 'sao': 98, 'cam': 99, 'sau': 100, 'giá': 101, 'này': 102, 'dùng': 103, 'ung': 104, 'nên': 105, 'hinh': 106, 'may': 107, 'van': 108, 'noi': 109, 'màu': 110, 'cai': 111, 'kém': 112, 'lan': 113, 'tin': 114, 'bao': 115, 'doi': 116, 'chi': 117, 'notnag': 118, 'se': 119, 'dat': 120, 'tra': 121, 'cũng': 122, 'giay': 123, 'thấy': 124, 'dau': 125, 'su': 126, 'nhận': 127, 'star': 128, 'roi': 129, 'gi': 130, 'hình': 131, 'lần': 132, 'hay': 133, 'sẽ': 134, 'day': 135, 'lắm': 136, 'cái': 137, 'ngon': 138, 'loi': 139, 'gì': 140, 'hơi': 141, 'hon': 142, 'nua': 143, 'nhieu': 144, 'mới': 145, 'toi': 146, 'tinh': 147, 'rồi': 148, 'phai': 149, 'mong': 150, 'còn': 151, 'hơn': 152, 'mat': 153, 'chua': 154, 'nhiều': 155, 'nữa': 156, 'em': 157, 'về': 158, 'luon': 159, 'k': 160, 'ngay': 161, 'chu': 162, 'tu': 163, 'đặt': 164, 'hop': 165, 'phải': 166, 'nao': 167, 'hộ': 168, 'di': 169, 'giày': 170, 'son': 171, 'để': 172, 'biet': 173, 'chung': 174, 'vi': 175, 'chỉ': 176, 'luôn': 177, 'sach': 178, 'ủng': 179, 'den': 180, 'tiki': 181, 'ca': 182, 'làm': 183, 'dai': 184, 'trả': 185, 'het': 186, 'nha': 187, 'nào': 188, 'e': 189, 'chưa': 190, 'nói': 191, 'dụng': 192, 'giong': 193, 'hai': 194, 'biết': 195, 'sách': 196, 'thu': 197, 'cảm': 198, 'đi': 199, 'long': 200, 'vay': 201, 'cả': 202, 'nhe': 203, 'len': 204, 'tam': 205, 'vẫn': 206, 'hết': 207, 'ơn': 208, 'sử': 209, 'cỡ': 210, 'ăn': 211, 'tay': 212, 'tình': 213, 'du': 214, 'vì': 215, 'mang': 216, 'pin': 217, 'vong': 218, 'vua': 219, 'gui': 220, 'dài': 221, 'cao': 222, 'vao': 223, 'một': 224, 'lên': 225, 'giống': 226, 'mot': 227, 'vậy': 228, 'ạ': 229, 'trang': 230, 'vào': 231, 'nho': 232, 'vừa': 233, 'khac': 234, 'lau': 235, 'thich': 236, 'đầu': 237, 'bo': 238, 'tôi': 239, 'sac': 240, 'thích': 241, 'xem': 242, 'ben': 243, 'ngày': 244, 'anh': 245, 'thuong': 246, 'cham': 247, 'nguoi': 248, 'kha': 249, 'người': 250, 'mui': 251, 'vọng': 252, 'nghe': 253, 'ý': 254, 'bán': 255, 'yeu': 256, 'luc': 257, 'xai': 258, 'máy': 259, 'bạn': 260, 'mo': 261, 'lời': 262, 'khá': 263, 'gửi': 264, 'kho': 265, 'dễ': 266, 'khác': 267, 'dan': 268, 'phan': 269, 'khach': 270, 'vo': 271, 'cu': 272, 'đúng': 273, 'ng': 274, 'tang': 275, 'te': 276, 'xài': 277, 'ai': 278, 'khách': 279, 'cac': 280, 'nhiệt': 281, 'sai': 282, 'ở': 283, 'cuc': 284, 'nhiet': 285, 'nhin': 286, 'tuy': 287, 'đến': 288, 'xong': 289, 'lâu': 290, 'đổi': 291, 'hộp': 292, 'ta': 293, 'thieu': 294, 'nhìn': 295, 'thất': 296, 'chậm': 297, 'yêu': 298, 'rẻ': 299, 'danh': 300, 'chuyen': 301, 'tren': 302, 'các': 303, 'tặng': 304, 'vai': 305, 'tiep': 306, 'mùi': 307, 'doc': 308, 'bên': 309, 'thật': 310, 'đọc': 311, 'lúc': 312, 'ưng': 313, 'thế': 314, 'hợp': 315, 'lòng': 316, 'nhé': 317, 'chay': 318, 'từ': 319, 'quan': 320, 'nhỏ': 321, 'thêm': 322, 'bảo': 323, 'lỗi': 324, 'tiếp': 325, 'cau': 326, 'keo': 327, 'dien': 328, 'xinh': 329, 'mặt': 330, 'nhắn': 331, 'trên': 332, 'gio': 333, 'theo': 334, 'han': 335, 'đó': 336, 'sang': 337, 'cẩn': 338, 'dinh': 339, 'bé': 340, 'nhat': 341, 'thôi': 342, 'mất': 343, 'thận': 344, 'hong': 345, 'nó': 346, 'chân': 347, 'ngoai': 348, 'tuong': 349, 'chinh': 350, 'đồng': 351, 'độ': 352, 'hài': 353, 'ki': 354, 'những': 355, 'sạc': 356, 'ảnh': 357, 'thể': 358, 'mac': 359, 'thanh': 360, 'truoc': 361, 'h': 362, 'cám': 363, 'tai': 364, 'thiếu': 365, 'mấy': 366, 'ghi': 367, 'trước': 368, 'chuẩn': 369, 'tệ': 370, 'binh': 371, 'quả': 372, 'chuan': 373, 'mẫu': 374, 'neu': 375, 'thom': 376, 'loai': 377, 'cực': 378, 'muon': 379, 'cong': 380, 'giờ': 381, 'hieu': 382, 'nếu': 383, 'sự': 384, 'chính': 385, 'xanh': 386, 'kinh': 387, 'nhau': 388, 'đây': 389, 'vấn': 390, 'đôi': 391, 'dù': 392, 'thơm': 393, 'nghi': 394, 'ky': 395, 'sieu': 396, 'nuoc': 397, 'điện': 398, 'deu': 399, 'đánh': 400, 'ngoài': 401, 'cach': 402, 'đồ': 403, 'số': 404, 'mai': 405, 'nước': 406, 'trung': 407, 'dây': 408, 'toan': 409, 'bình': 410, 'dao': 411, 'bat': 412, 'chứ': 413, 'tham': 414, 'muốn': 415, 'loại': 416, 'ổn': 417, 'mem': 418, 'siêu': 419, 'hồ': 420, 'nhiên': 421, 'bong': 422, 'uy': 423, 'cách': 424, 'ao': 425, 'gọi': 426, 'lay': 427, 'mỏng': 428, 'thương': 429, 'thử': 430, 'chai': 431, 'duong': 432, 'thứ': 433, 'thường': 434, 'thuc': 435, 'cuốn': 436, 'bang': 437, 'hanh': 438, 'chủ': 439, 'mềm': 440, 'nam': 441, 'hom': 442, 'đâu': 443, 'xau': 444, 'dam': 445, 'lua': 446, 'phần': 447, 'chịu': 448, 'chuyển': 449, 'tui': 450, 'cuon': 451, 'chiu': 452, 'cay': 453, 'xấu': 454, 'kieu': 455, 'êm': 456, 'giả': 457, 'nhà': 458, 'đều': 459, 'mặc': 460, 'nhất': 461, 'kiểu': 462, 'mở': 463, 'tac': 464, 'nhân': 465, 'man': 466, 'nhien': 467, 'kiem': 468, 'khó': 469, 'thang': 470, 'lấy': 471, 'che': 472, 'lo': 473, 'hu': 474, 'tư': 475, 'hãng': 476, 'chút': 477, 'toàn': 478, 'tác': 479, 'hoan': 480, 'c': 481, 'tâm': 482, 'hỏi': 483, 'nham': 484, 'đơn': 485, 'hoàn': 486, 'g': 487, 'ti': 488, 'boc': 489, 'hành': 490, 'cùng': 491, 'hoa': 492, 'hôm': 493, 'cứ': 494, 'ko': 495, 'chut': 496, 'tạm': 497, 'sim': 498, 'chang': 499, 'xa': 500, 'chon': 501, 'tan': 502, 'dieu': 503, 'chạy': 504, 'đợi': 505, 'ro': 506, 'hạn': 507, 'sáng': 508, 'huong': 509, 'áo': 510, 'mỗi': 511, 'mọi': 512, 'đủ': 513, 'chán': 514, 'tưởng': 515, 'nang': 516, 'điều': 517, 'ít': 518, 'ke': 519, 'lien': 520, 'mã': 521, 'tuc': 522, 'vải': 523, 'lun': 524, 'tem': 525, 'min': 526, 'báo': 527, 'le': 528, 'sua': 529, 'phu': 530, 'gan': 531, 'thoai': 532, 'cũ': 533, 'cần': 534, 'bộ': 535, 'deo': 536, 'khô': 537, 'đang': 538, 'tới': 539, 'cáo': 540, 'toc': 541, 'oi': 542, 'gay': 543, 'bỏ': 544, 'phong': 545, 'banh': 546, 'ly': 547, 'phi': 548, 'mieng': 549, 'quà': 550, 'thành': 551, 'lon': 552, 'cap': 553, 'đen': 554, 'viet': 555, 'check': 556, 'mịn': 557, 'dán': 558, 'túi': 559, 'chọn': 560, 'vô': 561, 'meo': 562, 'tục': 563, 'kiểm': 564, 'thực': 565, 'thong': 566, 'tả': 567, 'bằng': 568, 'cứng': 569, 'công': 570, 'bánh': 571, 'nhẹ': 572, 'kèm': 573, 'tự': 574, 'b': 575, 'rong': 576, 'tat': 577, 'chuc': 578, 'tính': 579, 'mop': 580, 'coi': 581, 'quay': 582, 'tieng': 583, 'giấy': 584, 'quyen': 585, 'truyện': 586, 'dính': 587, 'hiểu': 588, 'tháng': 589, 'chong': 590, 'đề': 591, 'truyen': 592, 'vui': 593, 'lừa': 594, 'iphone': 595, 'định': 596, 'kĩ': 597, 'n': 598, 'tuan': 599, 'vien': 600, 'nghĩ': 601, 'xin': 602, 'nội': 603, 'nhầm': 604, 'cầu': 605, 'xe': 606, 'rõ': 607, 'buon': 608, 'sinh': 609, 'hồi': 610, 'thiet': 611, 'phim': 612, 'nap': 613, 'ket': 614, 'kim': 615, 'câu': 616, 'bay': 617, 'miếng': 618, 'điểm': 619, 'kỹ': 620, 'môi': 621, 'lý': 622, 'trc': 623, 'bung': 624, 'nong': 625, 'tim': 626, 'giac': 627, 'vận': 628, 'hỏng': 629, 'kết': 630, 'thông': 631, 'dầu': 632, 'liên': 633, 'op': 634, 'quyển': 635, 'tuần': 636, 'bản': 637, 'tín': 638, 'rach': 639, 'lieu': 640, 'giam': 641, 'quat': 642, 'viec': 643, 'chuot': 644, 'liệu': 645, 'sữa': 646, 'giác': 647, 'diem': 648, 'hồng': 649, 'uong': 650, 'chỗ': 651, 'cha': 652, 'nhua': 653, 'rộng': 654, 'rách': 655, 'hien': 656, 'móp': 657, 'ba': 658, 'nut': 659, 'việc': 660, 'chap': 661, 'bia': 662, 'hi': 663, 'troi': 664, 'bọc': 665, 'đỏ': 666, 'tung': 667, 'lap': 668, 'hư': 669, 'ngan': 670, 'kì': 671, 'phí': 672, 'tro': 673, 'sale': 674, 'song': 675, 'mk': 676, 'nhựa': 677, 'rang': 678, 'dày': 679, 'vài': 680, 'loa': 681, 'dich': 682, 'trắng': 683, 'tại': 684, 'bim': 685, 'xay': 686, 'tiếng': 687, 'mi': 688, 'chị': 689, 'tiên': 690, 'dua': 691, 'thoại': 692, 'tí': 693, 'đường': 694, 'dem': 695, 'trai': 696, 'cang': 697, 'test': 698, 'nguyen': 699, 'phat': 700, 'hiện': 701, 'quần': 702, 'giầy': 703, 'ơi': 704, 'dịch': 705, 'bắt': 706, 'bàn': 707, 'chẳng': 708, 'xuat': 709, 'v': 710, 'giai': 711, 'hat': 712, 'phù': 713, 'phản': 714, 'hiệu': 715, 'méo': 716, 'ip': 717, 'nắp': 718, 'mô': 719, 'đeo': 720, 'giải': 721, 'cắm': 722, 'nổi': 723, 'ốp': 724, 'thai': 725, 'chup': 726, 'xiu': 727, 'vang': 728, 'đừng': 729, 'bền': 730, 'tre': 731, 'kia': 732, 'giảm': 733, 'sắc': 734, 'muc': 735, 'viên': 736, 'hut': 737, 'mắt': 738, 'xuất': 739, 'thiết': 740, 'nau': 741, 'quyết': 742, 'nóng': 743, 'mãi': 744, 'dép': 745, 'vị': 746, 'động': 747, 'vỡ': 748, 'quạt': 749, 'l': 750, 'chờ': 751, 'ah': 752, 'khuyen': 753, 'quyet': 754, 'phát': 755, 'tượng': 756, 'thân': 757, 'viết': 758, 'gioi': 759, 'lem': 760, 'mon': 761, 'vỏ': 762, 'form': 763, 'tất': 764, 'kính': 765, 'chụp': 766, 'keu': 767, 'hoc': 768, 'chuyện': 769, 'manh': 770, 'đầy': 771, 'li': 772, 'ngo': 773, 'ga': 774, 'bìa': 775, 'đảo': 776, 'vat': 777, 'xíu': 778, 'kien': 779, 'ay': 780, 'thái': 781, 'tiec': 782, 'cuoi': 783, 'nh': 784, 'tội': 785, 'dap': 786, 'uống': 787, 'boi': 788, 'chả': 789, 'mun': 790, 'nguyên': 791, 'ấy': 792, 'tận': 793, 'bam': 794, 'p': 795, 'thua': 796, 'đèn': 797, 'cân': 798, 'chuột': 799, 'mn': 800, 'gần': 801, 'phím': 802, 'yếu': 803, 'lum': 804, 'dám': 805, 'tap': 806, 'ntn': 807, 'hệ': 808, 'đế': 809, 'tiet': 810, 'hút': 811, 'kich': 812, 'ham': 813, 'càng': 814, 'đắt': 815, 'hạt': 816, 'tóc': 817, 'màn': 818, 'học': 819, 'mụn': 820, 'lớn': 821, 'gap': 822, 'chống': 823, 'bot': 824, 'dac': 825, 'choi': 826, 'combo': 827, 'dt': 828, 'buc': 829, 'rửa': 830, 'đấy': 831, 'dẫn': 832, 'văn': 833, 'ty': 834, 'ghe': 835, 'com': 836, 'từng': 837, 'chấp': 838, 'shiper': 839, 'wifi': 840, 'kêu': 841, 'cục': 842, 'cây': 843, 'thấm': 844, 'tiết': 845, 'tao': 846, 'dot': 847, 'xuoc': 848, 'quen': 849, 'chữ': 850, 'khoi': 851, 'đăng': 852, 'ngọt': 853, 'mát': 854, 'tray': 855, 'cơ': 856, 'sony': 857, 'ong': 858, 'lung': 859, 'canh': 860, 'review': 861, 'trợ': 862, 'lẽ': 863, 'chúc': 864, 'gb': 865, 'lot': 866, 'hoac': 867, 'goc': 868, 'moc': 869, 'led': 870, 'nút': 871, 'tập': 872, 'đặc': 873, 'xung': 874, 'tầm': 875, 'lop': 876, 'xước': 877, 'ngot': 878, 'lắp': 879, 'bỉm': 880, 'buồn': 881, 'lớp': 882, 'ấn': 883, 'bu': 884, 'tiếc': 885, 'hag': 886, 'na': 887, 'hướng': 888, 'bì': 889, 'hk': 890, 'khen': 891, 'đau': 892, 'ngu': 893, 'tốc': 894, 'sơ': 895, 'vẻ': 896, 'cat': 897, 'vàng': 898, 'suy': 899, 'thien': 900, 'chieu': 901, 'năm': 902, 'kiến': 903, 'samsung': 904, 'rua': 905, 'r': 906, 'ha': 907, 'sạch': 908, 'bit': 909, 'mạng': 910, 'nhac': 911, 'khau': 912, 'tế': 913, 'năng': 914, 'trach': 915, 'thèm': 916, 'duoi': 917, 'bất': 918, 'hy': 919, 'kỳ': 920, 'tranh': 921, 'cuối': 922, 'treo': 923, 'đt': 924, 'hề': 925, 'hỗ': 926, 'sh': 927, 'nhug': 928, 'tron': 929, 'mask': 930, 'đựng': 931, 'z': 932, 'x': 933, 'gãy': 934, 'truong': 935, 'dưỡng': 936, 'gon': 937, 'xet': 938, 'luu': 939, 'dòng': 940, 'quoc': 941, 'trầy': 942, 'cô': 943, 'chiếc': 944, 'lỏng': 945, 'soc': 946, 'tiện': 947, 'gion': 948, 'trách': 949, 'chiec': 950, 'cố': 951, 'kế': 952, 'món': 953, 'đưa': 954, 'vật': 955, 'gà': 956, 'tối': 957, 'kích': 958, 'cầm': 959, 'cháy': 960, 'troc': 961, 'nhạt': 962, 'sợ': 963, 'hao': 964, 'nguon': 965, 'xu': 966, 'đối': 967, 'ton': 968, 'rung': 969, 'ne': 970, 'hoặc': 971, 'hẳn': 972, 'ngờ': 973, 'giat': 974, 'tróc': 975, 'nồi': 976, 'khoa': 977, 'lực': 978, 'à': 979, 'bẩn': 980, 'gây': 981, 'cm': 982, 'lót': 983, 'muot': 984, 'nhiem': 985, 'chơi': 986, 'ứng': 987, 'khan': 988, 'khung': 989, 'giới': 990, 'quai': 991, 'dự': 992, 'haiz': 993, 'im': 994, 'chê': 995, 'bac': 996, 'mạnh': 997, 'tru': 998, 'nhiệm': 999, 'dặn': 1000}\n",
            "Kích thước của từ điển: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWueUg7454GY"
      },
      "source": [
        "Thống kê độ dài trung bình của một bình luận: 20 từ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "IUH99zWh56o0",
        "outputId": "f694e09b-6de3-4da0-ecb1-061874c74b8b"
      },
      "source": [
        "rev_len = [len(i) for i in x_train]\n",
        "pd.Series(rev_len).hist()\n",
        "plt.show()\n",
        "pd.Series(rev_len).describe()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    22521.000000\n",
              "mean        20.925758\n",
              "std         20.516213\n",
              "min          0.000000\n",
              "25%          9.000000\n",
              "50%         16.000000\n",
              "75%         26.000000\n",
              "max        556.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EhLHNEc6a2N"
      },
      "source": [
        "Quá trình Padding - chèn từng chuỗi để từng chuỗi có độ dài tối đa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-1Wf4Ul6Vei"
      },
      "source": [
        "def padding_(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJULg8TZ6e6R",
        "outputId": "7758efcb-d50d-4db6-fe9d-e78b2c9fb1ac"
      },
      "source": [
        "x_train_pad = padding_(x_train,100)\n",
        "x_test_pad = padding_(x_test,100)\n",
        "print(x_train_pad[0:5])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0 157 427 116  86\n",
            "  386  84 220 157 116  86 230  12   3   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0 170  24  27 572  73  31   7   4  20 191\n",
            "  174  50  53 134 325 563 179 168   1   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  81  16 536  58 318 282  40 520  12   3  86 115 438  40\n",
            "   12   3  15 121 139 193 446  39   2   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0 263 803  46 321  71  14\n",
            "   31  63 500  63 803 972 131 573 334 487  49 343 352 487 803 134 574 630\n",
            "  295 174 487 122  18 487 803  14 105 505 209 192 283  11  10 102  38  94\n",
            "  582  91 487 172 209 192   2   2   2   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  38  16  36  90 655 527  91 439   4  14 191 140  19  22  11  10\n",
            "    6 118  13   4  79  74   6   2   2   1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDTExJ4e6v8u"
      },
      "source": [
        "Tải và chuyển dữ liệu dưới dạng Tensor Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9i9K_IU6xRW"
      },
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
        "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFg0zkUd68rB"
      },
      "source": [
        "## Xây dựng mô hình"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_t2Dnq_67r0"
      },
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "  def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n",
        "        super(SentimentRNN,self).__init__()\n",
        " \n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        " \n",
        "        self.no_layers = no_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        #lstm\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
        "                           num_layers=no_layers, batch_first=True)\n",
        "        \n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "        # linear and sigmoid layer\n",
        "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "  def forward(self,x,hidden):\n",
        "        batch_size = x.size(0)\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
        "        # print(\"Embedim_shape:\",embeds.shape)  #[50, 500, 1000]\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        \n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n",
        "        \n",
        "        # dropout and fully connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "  def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        hidden = (h0,c0)\n",
        "        return hidden"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6NjS8Uq7MMs",
        "outputId": "2b1d071c-88fc-4eb7-e6c5-a9f651e71adc"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "no_layers = 2\n",
        "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
        "\n",
        "embedding_dim = 64\n",
        "output_dim = 1\n",
        "hidden_dim = 256\n",
        "\n",
        "\n",
        "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n",
        "\n",
        "#moving to gpu\n",
        "model.to(device)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(1001, 64)\n",
            "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZmNRyrS7gDV"
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# function to predict accuracy\n",
        "def acc(pred,label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTNsm5V-7mqu",
        "outputId": "525f6d60-7e2c-4728-db0a-2770b2f25058"
      },
      "source": [
        "clip = 5\n",
        "epochs = 10\n",
        "valid_loss_min = np.Inf\n",
        "# train for some number of epochs\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    # initialize hidden state \n",
        "    h = model.init_hidden(batch_size)\n",
        "    for inputs, labels in train_loader:\n",
        "        \n",
        "        inputs, labels = inputs.to(device), labels.to(device) \n",
        "        # print(\"inputs:\", inputs)\n",
        "        # print(\"inputs shape:\", inputs.shape)\n",
        "        # print(\"labels:\", labels)\n",
        "        # print(\"labels shape:\", labels.shape)\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "        # print(\"h:\", h)\n",
        "        # print(\"h shape:\", len(h))\n",
        "        model.zero_grad()\n",
        "        output,h = model(inputs,h)\n",
        "        \n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "        # calculating accuracy\n",
        "        accuracy = acc(output,labels)\n",
        "        train_acc += accuracy\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "    \n",
        "        \n",
        "    val_h = model.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "    for inputs, labels in valid_loader:\n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "            val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "            val_losses.append(val_loss.item())\n",
        "            \n",
        "            accuracy = acc(output,labels)\n",
        "            val_acc += accuracy\n",
        "            \n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}') \n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/sentiment_vietnamese/state_dict.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
        "        valid_loss_min = epoch_val_loss\n",
        "    print(25*'==')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "train_loss : 0.3383790370821953 val_loss : 0.309430827594174\n",
            "train_accuracy : 85.60898716753252 val_accuracy : 86.72951414068166\n",
            "Validation loss decreased (inf --> 0.309431).  Saving model ...\n",
            "==================================================\n",
            "Epoch 2\n",
            "train_loss : 0.2719956298172474 val_loss : 0.2716895123760317\n",
            "train_accuracy : 88.67279428089338 val_accuracy : 88.936082047032\n",
            "Validation loss decreased (0.309431 --> 0.271690).  Saving model ...\n",
            "==================================================\n",
            "Epoch 3\n",
            "train_loss : 0.2426095989677641 val_loss : 0.2735724522119359\n",
            "train_accuracy : 90.24910083921674 val_accuracy : 88.7496115197348\n",
            "==================================================\n",
            "Epoch 4\n",
            "train_loss : 0.215847339572178 val_loss : 0.2700759333418441\n",
            "train_accuracy : 91.49238488521824 val_accuracy : 88.90500362581581\n",
            "Validation loss decreased (0.271690 --> 0.270076).  Saving model ...\n",
            "==================================================\n",
            "Epoch 5\n",
            "train_loss : 0.18897571999165746 val_loss : 0.2697471851396128\n",
            "train_accuracy : 92.82891523466986 val_accuracy : 89.19506889050037\n",
            "Validation loss decreased (0.270076 --> 0.269747).  Saving model ...\n",
            "==================================================\n",
            "Epoch 6\n",
            "train_loss : 0.1564493812703424 val_loss : 0.2864238181262436\n",
            "train_accuracy : 94.03223657919276 val_accuracy : 89.37117994405884\n",
            "==================================================\n",
            "Epoch 7\n",
            "train_loss : 0.1196428662745489 val_loss : 0.3339811526045898\n",
            "train_accuracy : 95.76839394343057 val_accuracy : 88.936082047032\n",
            "==================================================\n",
            "Epoch 8\n",
            "train_loss : 0.0919489223199586 val_loss : 0.3580080739709843\n",
            "train_accuracy : 96.66533457661738 val_accuracy : 88.68745467730238\n",
            "==================================================\n",
            "Epoch 9\n",
            "train_loss : 0.06385061715677795 val_loss : 0.40397392179566033\n",
            "train_accuracy : 97.78873051818303 val_accuracy : 89.27794468041024\n",
            "==================================================\n",
            "Epoch 10\n",
            "train_loss : 0.045659872096601044 val_loss : 0.4745783697948863\n",
            "train_accuracy : 98.35708893921229 val_accuracy : 89.12255257432923\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}