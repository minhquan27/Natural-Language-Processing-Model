{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_VietNamese_reviewshopping.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwleBYnio6YT"
      },
      "source": [
        "# **Ph√¢n lo·∫°i s·∫Øc th√°i b√¨nh lu·∫≠n kh√°ch h√†ng** (Vietnamese sentiment analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlTfHNJ9rdFv"
      },
      "source": [
        "## T√≥m t·∫Øt ph∆∞∆°ng th·ª©c th·ª±c hi·ªán b√†i to√°n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K2zExnypXkV"
      },
      "source": [
        "1. Cu·ªôc thi v√† d·ªØ li·ªáu\n",
        "- Cu·ªôc thi AIVIVN: https://www.aivivn.com/contests/1\n",
        "- D·ªØ li·ªáu:  file_train: train.crash, file test: test.crash, sample_submission.csv. C√¢u b√¨nh lu·∫≠n c√≥ ƒë·ªô d√†i b·∫•t k·ª≥ ƒë∆∞·ª£c g√°n nh√£n 0 ho·∫∑c 1, trong ƒë√≥ 1: b√¨nh lu·∫≠n ti√™u c·ª±c, 0: b√¨nh lu·∫≠n t√≠ch c·ª±c. T·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán v√† t·∫≠p d·ªØ li·ªáu ki·ªÉm tra train.crash: 16086 b√¨nh lu·∫≠n, test.crash: 10980 b√¨nh lu·∫≠n.\n",
        "- Nhi·ªám v·ª•: X√°c ƒë·ªãnh b√¨nh lu·∫≠n mang √Ω nghƒ©a ti√™u c·ª±c hay t√≠ch c·ª±c.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XtL1lj0p681"
      },
      "source": [
        "2. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu\n",
        "- Chu·∫©n h√≥a c√°c k√Ω t·ª± b·ªã k√©o d√†i. VD: chi·∫øc √°o n√†y ƒë·∫πp quaaa -> chi·∫øc √°o n√†y ƒë·∫πp qu√°,...\n",
        "- Chu·∫©n h√≥a m·ªôt s·ªë sentiment word. VD \"okie\"-> \"ok\", \"k\" ->\"kh√¥ng\", \"tot\"->\"t·ªët\",... \n",
        "- ƒê∆∞a c√°c icon v·ªÅ t√≠ch c·ª±c (positive) hay ti√™u c·ª±c (nagative). VD: ;) -> positive, :(( ->nagative. \n",
        "- Lo·∫°i b·ªè c√°c d·∫•u c√¢u v√† c√°c k√Ω t·ª± nhi·ªÖu.\n",
        "- M·ªü r·ªông data b·∫±ng c√°ch th√™m c√°c c√¢u b√¨nh lu·∫≠n kh√¥ng d·∫•u. Th·ª±c t·∫ø, nhi·ªÅu review c≈©ng kh√¥ng c√≥ d·∫•u.\n",
        "- M·ªü r·ªông train data b·∫±ng c√°ch th√™m v√†o c√°c m·∫´u m·ªõi l√† l·∫•y t·ª´ ch√≠nh 2 t·ª´ ƒëi·ªÉn, t·ª´ ƒëi·ªÉn positive (c√°c t·ª´ ng·ªØ mang y·∫øu t·ªë t√≠ch c·ª±c) v√† t·ª´ ƒëi·ªÉn nagative (c√°c t·ª´ ng·ªØ c√≥ √Ω nghƒ©a ti√™u c·ª±c)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKng3e_QqmLc"
      },
      "source": [
        "3. L·ª±a ch·ªçn v√† x√¢y d·ª±ng m√¥ h√¨nh\n",
        "- C√°c m√¥ h√¨nh machine-learning c∆° b·∫£n d√πng ƒë·ªÉ ph√¢n l·ªõp d·ªØ li·ªáu: SVM, Navie Bayes, Logistic_Regression, Decision_Tree.\n",
        "- C√°c m√¥ h√¨nh deep-learning: M·∫°ng neuron t√≠ch ch·∫≠p, m·∫°ng neuron h·ªìi ti·∫øp, m·∫°ng LSTM.\n",
        "- L·ª±a ch·ªçn: M·∫°ng neuron h·ªìi ti·∫øp hai chi·ªÅu v·ªõi ki·∫øn tr√∫c l√† LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lANmHtEGrPyb"
      },
      "source": [
        "4. Quy tr√¨nh th·ª±c hi·ªán\n",
        "- B∆∞·ªõc 1. L·∫•y ƒë∆∞·ª£c c√°c tr∆∞·ªùng d·ªØ li·ªáu: id, label, review. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu.\n",
        "\n",
        "- B∆∞·ªõc 2. S·ª≠ d·ª•ng c√°c c√¥ng c·ª• ƒë·ªÉ Word Embedding c√°c t·ª´.\n",
        "\n",
        "- B∆∞·ªõc 3. Chu·∫©n h√≥a ƒë·ªô d√†i c√°c c√¢u trong d·ªØ li·ªáu train. Chia t·∫≠p d·ªØ li·ªáu theo t·ª∑ l·ªá 7/3.\n",
        "\n",
        "- B∆∞·ªõc 4. ƒê∆∞a v√†o c√°c m√¥ h√¨nh. Luy·ªán m√¥ h√¨nh.\n",
        "\n",
        "- B∆∞·ªõc 5. Predict v·ªõi d·ªØ li·ªáu validation_data. Predict v·ªõi d·ªØ li·ªáu test.\n",
        "\n",
        "- B∆∞·ªõc 6. ƒê√°nh gi√° ƒë·ªô ch√≠nh x√°c v√† k·∫øt lu·∫≠n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-LZSfTfrvct"
      },
      "source": [
        "## C√†i ƒë·∫∑t pytorch v√† google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBQ17ROZr0bS"
      },
      "source": [
        "C√†i ƒëƒÉt pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjFe0Vlcr50G",
        "outputId": "7047f1a6-e207-4551-c37e-f940aa355e53"
      },
      "source": [
        "pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.1+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 834.1MB 1.3MB/s eta 0:14:35tcmalloc: large alloc 1147494400 bytes == 0x55c22d9cc000 @  0x7f6a92537615 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c487f0 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4d493e1 0x55c1f4ca96a9 0x55c1f4c14cc4 0x55c1f4bd5559 0x55c1f4c494f8 0x55c1f4bd630a 0x55c1f4c443b5 0x55c1f4c437ad 0x55c1f4bd63ea 0x55c1f4c443b5 0x55c1f4bd630a 0x55c1f4c443b5\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 1055.7MB 1.2MB/s eta 0:12:31tcmalloc: large alloc 1434370048 bytes == 0x55c272022000 @  0x7f6a92537615 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c487f0 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4d493e1 0x55c1f4ca96a9 0x55c1f4c14cc4 0x55c1f4bd5559 0x55c1f4c494f8 0x55c1f4bd630a 0x55c1f4c443b5 0x55c1f4c437ad 0x55c1f4bd63ea 0x55c1f4c443b5 0x55c1f4bd630a 0x55c1f4c443b5\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 1336.2MB 1.5MB/s eta 0:07:21tcmalloc: large alloc 1792966656 bytes == 0x55c1f6e54000 @  0x7f6a92537615 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c487f0 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4d493e1 0x55c1f4ca96a9 0x55c1f4c14cc4 0x55c1f4bd5559 0x55c1f4c494f8 0x55c1f4bd630a 0x55c1f4c443b5 0x55c1f4c437ad 0x55c1f4bd63ea 0x55c1f4c443b5 0x55c1f4bd630a 0x55c1f4c443b5\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1691.1MB 1.3MB/s eta 0:03:39tcmalloc: large alloc 2241208320 bytes == 0x55c261c3c000 @  0x7f6a92537615 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c487f0 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4c44853 0x55c1f4cc6e36 0x55c1f4d493e1 0x55c1f4ca96a9 0x55c1f4c14cc4 0x55c1f4bd5559 0x55c1f4c494f8 0x55c1f4bd630a 0x55c1f4c443b5 0x55c1f4c437ad 0x55c1f4bd63ea 0x55c1f4c443b5 0x55c1f4bd630a 0x55c1f4c443b5\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1982.2MB 1.2MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0x55c2e759e000 @  0x7f6a925361e7 0x55c1f4c07f37 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4bd630a 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4c434ae\n",
            "tcmalloc: large alloc 2477727744 bytes == 0x55c3d1cbe000 @  0x7f6a92537615 0x55c1f4bd1cdc 0x55c1f4cb152a 0x55c1f4bd4afd 0x55c1f4cc5fed 0x55c1f4c48988 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4460e 0x55c1f4bd630a 0x55c1f4c4460e 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4c434ae 0x55c1f4bd63ea 0x55c1f4c4532a 0x55c1f4c434ae 0x55c1f4bd6a81\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1982.2MB 5.3kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.6MB 235kB/s \n",
            "\u001b[?25hCollecting torchaudio===0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.9MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhKMRkgVtkwB"
      },
      "source": [
        "K·∫øt n·ªëi google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-OMoMN2tj3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ac581d-094a-4300-9637-9d9a0e3962a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PxAHKiAuD0w"
      },
      "source": [
        "C√†i ƒë·∫∑t th∆∞ vi√™n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhQtlXJzuF95"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from nltk.corpus import stopwords \n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_P1V2ZeuSbi"
      },
      "source": [
        "## Hi·ªÉn th·ªã v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiLjOdsc03Rk",
        "outputId": "cbdd2764-7b05-41cb-a7f9-a41f799f15ff"
      },
      "source": [
        "pip install pyvi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyvi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/e1/0e5bc6b5e3327b9385d6e0f1b0a7c0404f28b74eb6db59a778515b30fd9c/pyvi-0.1-py2.py3-none-any.whl (8.5MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.5MB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.0.1)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 747kB 42.8MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.7 pyvi-0.1 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo50D3Q_vw15"
      },
      "source": [
        "import pandas as pd\n",
        "from pyvi import ViTokenizer\n",
        "import re\n",
        "import string\n",
        "import codecs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39UwyuNsvmtp"
      },
      "source": [
        "X√¢y d·ª±ng c√°c t·ª´ ƒëi·ªÉn t√≠ch c·ª±c, t·ª´ ƒëi·ªÉn ti√™u c·ª±c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeIlDQVLuXau"
      },
      "source": [
        "path = \"/content/gdrive/MyDrive/sentiment_vietnamese/sentiment_dicts\"\n",
        "path_nag = path + '/nag.txt'\n",
        "path_pos = path + '/pos.txt'\n",
        "path_not = path + '/not.txt'\n",
        "VN_CHARS_LOWER = u'·∫°·∫£√£√†√°√¢·∫≠·∫ß·∫•·∫©·∫´ƒÉ·∫Ø·∫±·∫∑·∫≥·∫µ√≥√≤·ªç√µ·ªè√¥·ªô·ªï·ªó·ªì·ªë∆°·ªù·ªõ·ª£·ªü·ª°√©√®·∫ª·∫π·∫Ω√™·∫ø·ªÅ·ªá·ªÉ·ªÖ√∫√π·ª•·ªß≈©∆∞·ª±·ªØ·ª≠·ª´·ª©√≠√¨·ªã·ªâƒ©√Ω·ª≥·ª∑·ªµ·ªπƒë√∞'\n",
        "VN_CHARS_UPPER = u'·∫†·∫¢√É√Ä√Å√Ç·∫¨·∫¶·∫§·∫®·∫™ƒÇ·∫Æ·∫∞·∫∂·∫≤·∫¥√ì√í·ªå√ï·ªé√î·ªò·ªî·ªñ·ªí·ªê∆†·ªú·ªö·ª¢·ªû·ª†√â√à·∫∫·∫∏·∫º√ä·∫æ·ªÄ·ªÜ·ªÇ·ªÑ√ö√ô·ª§·ª¶≈®∆Ø·ª∞·ªÆ·ª¨·ª™·ª®√ç√å·ªä·ªàƒ®√ù·ª≤·ª∂·ª¥·ª∏√êƒê'\n",
        "VN_CHARS = VN_CHARS_LOWER + VN_CHARS_UPPER"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqIocZZYwyLH"
      },
      "source": [
        "def diction_nag_pos_not():\n",
        "    with codecs.open(path_nag, 'r', encoding='UTF-8') as f:\n",
        "        nag = f.readlines()\n",
        "    nag_list = [n.replace('\\n', '') for n in nag]\n",
        "\n",
        "    with codecs.open(path_pos, 'r', encoding='UTF-8') as f:\n",
        "        pos = f.readlines()\n",
        "    pos_list = [n.replace('\\n', '') for n in pos]\n",
        "    with codecs.open(path_not, 'r', encoding='UTF-8') as f:\n",
        "        not_ = f.readlines()\n",
        "    not_list = [n.replace('\\n', '') for n in not_]\n",
        "    return nag_list, pos_list, not_list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyAeR42Lw2dr"
      },
      "source": [
        "nag_list, pos_list, not_list = diction_nag_pos_not()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41ZppTlow6sX",
        "outputId": "5d575786-a197-48dc-b113-743a7898e12d"
      },
      "source": [
        "print(nag_list[0:5])\n",
        "print(pos_list[0:5])\n",
        "print(not_list) # T·∫≠p c√°c t·ª´ ph·ªß ƒë·ªãnh"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['b·∫•t l·ª£i', 'ch√°n', 'ch·∫≠t h·∫πch·∫≠t', 'ch·∫≠t', 't·ª©c gi·∫≠n']\n",
            "['∆∞ng √Ω', '∆∞ng', 'k·ªπ', 'ƒë∆∞·ª£c', '√¥ k√™']\n",
            "['kh√¥ng', 'v√¥', 'ch·∫≥ng', 'ƒë·∫øch', 'ch∆∞a', 'ƒë√©o', 'k√©m', 'n·ªè', 'not']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiUcFpmnxOfH"
      },
      "source": [
        "H√†m b·ªè d·∫•u cho text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8emTBn0xXPo"
      },
      "source": [
        "def no_marks(s):\n",
        "    __INTAB = [ch for ch in VN_CHARS]\n",
        "    __OUTTAB = \"a\" * 17 + \"o\" * 17 + \"e\" * 11 + \"u\" * 11 + \"i\" * 5 + \"y\" * 5 + \"d\" * 2\n",
        "    __OUTTAB += \"A\" * 17 + \"O\" * 17 + \"E\" * 11 + \"U\" * 11 + \"I\" * 5 + \"Y\" * 5 + \"D\" * 2\n",
        "    __r = re.compile(\"|\".join(__INTAB))\n",
        "    __replaces_dict = dict(zip(__INTAB, __OUTTAB))\n",
        "    result = __r.sub(lambda m: __replaces_dict[m.group(0)], s)\n",
        "    return result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBg11DEfxeZ4",
        "outputId": "54f3d850-5ffa-4777-8795-4b9e659c5084"
      },
      "source": [
        "s = \"s·∫£n ph·∫©m n√†y r·∫•t ƒë·∫πp\"\n",
        "print(no_marks(s))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "san pham nay rat dep\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot72fWe6xpwX"
      },
      "source": [
        "### H√†m chu·∫©n ho√°: \n",
        "- lo·∫°i b·ªè c√°c k√Ω t·ª± k√©o d√†i\n",
        "- chuy·ªÉn text th√†nh ch·ªØ th∆∞·ªùng\n",
        "- th√™m feauture cho c√°c sentiment work: \"√Åo n√†y ƒë·∫πp\" chuy·ªÉn th√†nh \"√Åo n√†y ƒë·∫πp positive\".  \n",
        "- lo·∫°i b·ªè ch·∫•m c√¢u.\n",
        "- chu·∫©n ho√° c√°c t·ª´ ti·∫øng Anh, c√°c icon, c√°c t·ª´ vi·∫øt t·∫Øt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbrwOmj-ycka"
      },
      "source": [
        "def normalize_text(text):\n",
        "    # Remove c√°c k√Ω t·ª± k√©o d√†i: vd: ƒë·∫πppppppp\n",
        "    text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng\n",
        "    text = text.lower()\n",
        "\n",
        "    # Chu·∫©n h√≥a ti·∫øng Vi·ªát, x·ª≠ l√Ω emoj, chu·∫©n h√≥a ti·∫øng Anh, thu·∫≠t ng·ªØ\n",
        "    replace_list = {\n",
        "        '√≤a': 'o√†', '√≥a': 'o√°', '·ªèa': 'o·∫£', '√µa': 'o√£', '·ªça': 'o·∫°', '√≤e': 'o√®', '√≥e': 'o√©', '·ªèe': 'o·∫ª',\n",
        "        '√µe': 'o·∫Ω', '·ªçe': 'o·∫π', '√πy': 'u·ª≥', '√∫y': 'u√Ω', '·ªßy': 'u·ª∑', '≈©y': 'u·ªπ', '·ª•y': 'u·ªµ', 'u·∫£': '·ªßa',\n",
        "        'aÃâ': '·∫£', '√¥ÃÅ': '·ªë', 'u¬¥': '·ªë', '√¥ÃÉ': '·ªó', '√¥ÃÄ': '·ªì', '√¥Ãâ': '·ªï', '√¢ÃÅ': '·∫•', '√¢ÃÉ': '·∫´', '√¢Ãâ': '·∫©',\n",
        "        '√¢ÃÄ': '·∫ß', 'oÃâ': '·ªè', '√™ÃÄ': '·ªÅ', '√™ÃÉ': '·ªÖ', 'ƒÉÃÅ': '·∫Ø', 'uÃâ': '·ªß', '√™ÃÅ': '·∫ø', '∆°Ãâ': '·ªü', 'iÃâ': '·ªâ',\n",
        "        'eÃâ': '·∫ª', '√†k': u' √† ', 'aÀã': '√†', 'iÀã': '√¨', 'ƒÉ¬¥': '·∫Ø', '∆∞Ãâ': '·ª≠', 'eÀú': '·∫Ω', 'yÀú': '·ªπ', 'a¬¥': '√°',\n",
        "        # Quy c√°c icon v·ªÅ 2 lo·∫°i emoj: T√≠ch c·ª±c ho·∫∑c ti√™u c·ª±c\n",
        "        \"üëπ\": \"nagative\", \"üëª\": \"positive\", \"üíÉ\": \"positive\", 'ü§ô': ' positive ', 'üëç': ' positive ',\n",
        "        \"üíÑ\": \"positive\", \"üíé\": \"positive\", \"üí©\": \"positive\", \"üòï\": \"nagative\", \"üò±\": \"nagative\", \"üò∏\": \"positive\",\n",
        "        \"üòæ\": \"nagative\", \"üö´\": \"nagative\", \"ü§¨\": \"nagative\", \"üßö\": \"positive\", \"üß°\": \"positive\", 'üê∂': ' positive ',\n",
        "        'üëé': ' nagative ', 'üò£': ' nagative ', '‚ú®': ' positive ', '‚ù£': ' positive ', '‚òÄ': ' positive ',\n",
        "        '‚ô•': ' positive ', 'ü§©': ' positive ', 'like': ' positive ', 'üíå': ' positive ',\n",
        "        'ü§£': ' positive ', 'üñ§': ' positive ', 'ü§§': ' positive ', ':(': ' nagative ', 'üò¢': ' nagative ',\n",
        "        '‚ù§': ' positive ', 'üòç': ' positive ', 'üòò': ' positive ', 'üò™': ' nagative ', 'üòä': ' positive ',\n",
        "        '?': ' ? ', 'üòÅ': ' positive ', 'üíñ': ' positive ', 'üòü': ' nagative ', 'üò≠': ' nagative ',\n",
        "        'üíØ': ' positive ', 'üíó': ' positive ', '‚ô°': ' positive ', 'üíú': ' positive ', 'ü§ó': ' positive ',\n",
        "        '^^': ' positive ', 'üò®': ' nagative ', '‚ò∫': ' positive ', 'üíã': ' positive ', 'üëå': ' positive ',\n",
        "        'üòñ': ' nagative ', 'üòÄ': ' positive ', ':((': ' nagative ', 'üò°': ' nagative ', 'üò†': ' nagative ',\n",
        "        'üòí': ' nagative ', 'üôÇ': ' positive ', 'üòè': ' nagative ', 'üòù': ' positive ', 'üòÑ': ' positive ',\n",
        "        'üòô': ' positive ', 'üò§': ' nagative ', 'üòé': ' positive ', 'üòÜ': ' positive ', 'üíö': ' positive ',\n",
        "        '‚úå': ' positive ', 'üíï': ' positive ', 'üòû': ' nagative ', 'üòì': ' nagative ', 'Ô∏èüÜóÔ∏è': ' positive ',\n",
        "        'üòâ': ' positive ', 'üòÇ': ' positive ', ':v': '  positive ', '=))': '  positive ', 'üòã': ' positive ',\n",
        "        'üíì': ' positive ', 'üòê': ' nagative ', ':3': ' positive ', 'üò´': ' nagative ', 'üò•': ' nagative ',\n",
        "        'üòÉ': ' positive ', 'üò¨': ' üò¨ ', 'üòå': ' üòå ', 'üíõ': ' positive ', 'ü§ù': ' positive ', 'üéà': ' positive ',\n",
        "        'üòó': ' positive ', 'ü§î': ' nagative ', 'üòë': ' nagative ', 'üî•': ' nagative ', 'üôè': ' nagative ',\n",
        "        'üÜó': ' positive ', 'üòª': ' positive ', 'üíô': ' positive ', 'üíü': ' positive ',\n",
        "        'üòö': ' positive ', '‚ùå': ' nagative ', 'üëè': ' positive ', ';)': ' positive ', '<3': ' positive ',\n",
        "        'üåù': ' positive ', 'üå∑': ' positive ', 'üå∏': ' positive ', 'üå∫': ' positive ',\n",
        "        'üåº': ' positive ', 'üçì': ' positive ', 'üêÖ': ' positive ', 'üêæ': ' positive ', 'üëâ': ' positive ',\n",
        "        'üíê': ' positive ', 'üíû': ' positive ', 'üí•': ' positive ', 'üí™': ' positive ',\n",
        "        'üí∞': ' positive ', 'üòá': ' positive ', 'üòõ': ' positive ', 'üòú': ' positive ',\n",
        "        'üôÉ': ' positive ', 'ü§ë': ' positive ', 'ü§™': ' positive ', '‚òπ': ' nagative ', 'üíÄ': ' nagative ',\n",
        "        'üòî': ' nagative ', 'üòß': ' nagative ', 'üò©': ' nagative ', 'üò∞': ' nagative ', 'üò≥': ' nagative ',\n",
        "        'üòµ': ' nagative ', 'üò∂': ' nagative ', 'üôÅ': ' nagative ',\n",
        "        # Chu·∫©n h√≥a 1 s·ªë sentiment words/English words\n",
        "        ':))': '  positive ', ':)': ' positive ', '√¥ k√™i': ' ok ', 'okie': ' ok ', ' o k√™ ': ' ok ',\n",
        "        'okey': ' ok ', '√¥k√™': ' ok ', 'oki': ' ok ', ' oke ': ' ok ', ' okay': ' ok ', 'ok√™': ' ok ',\n",
        "        ' tks ': u' c√°m ∆°n ', 'thks': u' c√°m ∆°n ', 'thanks': u' c√°m ∆°n ', 'ths': u' c√°m ∆°n ', 'thank': u' c√°m ∆°n ',\n",
        "        '‚≠ê': 'star ', '*': 'star ', 'üåü': 'star ', 'üéâ': u' positive ',\n",
        "        'kg ': u' kh√¥ng ', 'not': u' kh√¥ng ', u' kg ': u' kh√¥ng ', '\"k ': u' kh√¥ng ', ' kh ': u' kh√¥ng ',\n",
        "        'k√¥': u' kh√¥ng ', 'hok': u' kh√¥ng ', ' kp ': u' kh√¥ng ph·∫£i ', u' k√¥ ': u' kh√¥ng ', '\"ko ': u' kh√¥ng ',\n",
        "        u' ko ': u' kh√¥ng ', u' k ': u' kh√¥ng ', 'khong': u' kh√¥ng ', u' hok ': u' kh√¥ng ',\n",
        "        'he he': ' positive ', 'hehe': ' positive ', 'hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',\n",
        "        ' lol ': ' nagative ', ' cc ': ' nagative ', 'cute': u' d·ªÖ th∆∞∆°ng ', 'huhu': ' nagative ', ' vs ': u' v·ªõi ',\n",
        "        'wa': ' qu√° ', 'w√°': u' qu√°', 'j': u' g√¨ ', '‚Äú': ' ',\n",
        "        ' sz ': u' c·ª° ', 'size': u' c·ª° ', u' ƒëx ': u' ƒë∆∞·ª£c ', 'dk': u' ƒë∆∞·ª£c ', 'dc': u' ƒë∆∞·ª£c ', 'ƒëk': u' ƒë∆∞·ª£c ',\n",
        "        'ƒëc': u' ƒë∆∞·ª£c ', 'authentic': u' chu·∫©n ch√≠nh h√£ng ', u' aut ': u' chu·∫©n ch√≠nh h√£ng ',\n",
        "        u' auth ': u' chu·∫©n ch√≠nh h√£ng ', 'thick': u' positive ', 'store': u' c·ª≠a h√†ng ',\n",
        "        'shop': u' c·ª≠a h√†ng ', 'sp': u' s·∫£n ph·∫©m ', 'gud': u' t·ªët ', 'god': u' t·ªët ', 'wel done': ' t·ªët ',\n",
        "        'good': u' t·ªët ', 'g√∫t': u' t·ªët ',\n",
        "        's·∫•u': u' x·∫•u ', 'gut': u' t·ªët ', u' tot ': u' t·ªët ', u' nice ': u' t·ªët ', 'perfect': 'r·∫•t t·ªët',\n",
        "        'bt': u' b√¨nh th∆∞·ªùng ',\n",
        "        'time': u' th·ªùi gian ', 'q√°': u' qu√° ', u' ship ': u' giao h√†ng ', u' m ': u' m√¨nh ', u' mik ': u' m√¨nh ',\n",
        "        '√™Ãâ': '·ªÉ', 'product': 's·∫£n ph·∫©m', 'quality': 'ch·∫•t l∆∞·ª£ng', 'chat': ' ch·∫•t ', 'excelent': 'ho√†n h·∫£o',\n",
        "        'bad': 't·ªá', 'fresh': ' t∆∞∆°i ', 'sad': ' t·ªá ',\n",
        "        'date': u' h·∫°n s·ª≠ d·ª•ng ', 'hsd': u' h·∫°n s·ª≠ d·ª•ng ', 'quickly': u' nhanh ', 'quick': u' nhanh ',\n",
        "        'fast': u' nhanh ', 'delivery': u' giao h√†ng ', u' s√≠p ': u' giao h√†ng ',\n",
        "        'beautiful': u' ƒë·∫πp tuy·ªát v·ªùi ', u' tl ': u' tr·∫£ l·ªùi ', u' r ': u' r·ªìi ', u' shopE ': u' c·ª≠a h√†ng ',\n",
        "        u' order ': u' ƒë·∫∑t h√†ng ',\n",
        "        'ch·∫•t lg': u' ch·∫•t l∆∞·ª£ng ', u' sd ': u' s·ª≠ d·ª•ng ', u' dt ': u' ƒëi·ªán tho·∫°i ', u' nt ': u' nh·∫Øn tin ',\n",
        "        u' tl ': u' tr·∫£ l·ªùi ', u' s√†i ': u' x√†i ', u'bjo': u' bao gi·ªù ',\n",
        "        'thik': u' th√≠ch ', u' sop ': u' c·ª≠a h√†ng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' r·∫•t ',\n",
        "        u'qu·∫£ ng ': u' qu·∫£ng  ',\n",
        "        'dep': u' ƒë·∫πp ', u' xau ': u' x·∫•u ', 'delicious': u' ngon ', u'h√†g': u' h√†ng ', u'q·ªßa': u' qu·∫£ ',\n",
        "        'iu': u' y√™u ', 'fake': u' gi·∫£ m·∫°o ', 'trl': 'tr·∫£ l·ªùi', '><': u' positive ',\n",
        "        ' por ': u' t·ªá ', ' poor ': u' t·ªá ', 'ib': u' nh·∫Øn tin ', 'rep': u' tr·∫£ l·ªùi ', u'fback': ' feedback ',\n",
        "        'fedback': ' feedback ',\n",
        "        # d∆∞·ªõi 3* quy v·ªÅ 1*, tr√™n 3* quy v·ªÅ 5*\n",
        "        '6 sao': ' 5star ', '6 star': ' 5star ', '5star': ' 5star ', '5 sao': ' 5star ', '5sao': ' 5star ',\n",
        "        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ', '2 sao': ' 1star ', '2sao': ' 1star ',\n",
        "        '2 starstar': ' 1star ', '1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ', }\n",
        "\n",
        "    for k, v in replace_list.items():\n",
        "        text = text.replace(k, v)\n",
        "\n",
        "    # chuyen punctuation th√†nh space\n",
        "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    text = ViTokenizer.tokenize(text)\n",
        "    texts = text.split()\n",
        "    len_text = len(texts)\n",
        "    nag_list, pos_list, not_list = diction_nag_pos_not()\n",
        "    texts = [t.replace('_', ' ') for t in texts]\n",
        "    for i in range(len_text):\n",
        "        cp_text = texts[i]\n",
        "        if cp_text in not_list:  # X·ª≠ l√Ω v·∫•n ƒë·ªÅ ph·ªß ƒë·ªãnh (VD: √°o n√†y ch·∫≥ng ƒë·∫πp--> √°o n√†y notpos)\n",
        "            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1\n",
        "\n",
        "            for j in range(numb_word):\n",
        "                if texts[i + j + 1] in pos_list:\n",
        "                    texts[i] = 'notpos'\n",
        "                    texts[i + j + 1] = ''\n",
        "\n",
        "                if texts[i + j + 1] in nag_list:\n",
        "                    texts[i] = 'notnag'\n",
        "                    texts[i + j + 1] = ''\n",
        "        else:  # Th√™m feature cho nh·ªØng sentiment words (√°o n√†y ƒë·∫πp--> √°o n√†y ƒë·∫πp positive)\n",
        "            if cp_text in pos_list:\n",
        "                texts.append('positive')\n",
        "            elif cp_text in nag_list:\n",
        "                texts.append('nagative')\n",
        "\n",
        "    text = u' '.join(texts)\n",
        "\n",
        "    # remove n·ªët nh·ªØng k√Ω t·ª± th·ª´a th√£i\n",
        "    text = text.replace(u'\"', u' ')\n",
        "    text = text.replace(u'Ô∏è', u'')\n",
        "    text = text.replace('üèª', '')\n",
        "    return text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAjYn-6ayv00"
      },
      "source": [
        "### Hi·ªÉn th·ªã v√† ph√¢n t√≠ch d·ªØ li·ªáu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJOqx_HLy2CG"
      },
      "source": [
        "class DataSource(object):\n",
        "    def _load_raw_data(self, filename, is_train=True):\n",
        "        a = []\n",
        "        b = []\n",
        "        regex = 'train_'\n",
        "        if not is_train:\n",
        "            regex = 'test_'\n",
        "        with open(filename, 'r', encoding='utf8') as file:\n",
        "            for line in file:\n",
        "                if regex in line:\n",
        "                    b.append(a)\n",
        "                    a = [line]\n",
        "                elif line != '\\n':\n",
        "                    a.append(line)\n",
        "        b.append(a)\n",
        "        return b[1:]\n",
        "\n",
        "    def _create_row(self, sample, is_train=True):\n",
        "        d = {}\n",
        "        d['id'] = sample[0].replace('\\n', '')\n",
        "        review = \"\"\n",
        "        if is_train:\n",
        "            for clause in sample[1:-1]:\n",
        "                review += clause.replace('\\n', '').strip()\n",
        "            d['label'] = int(sample[-1].replace('\\n', ''))\n",
        "        else:\n",
        "            for clause in sample[1:]:\n",
        "                review += clause.replace('\\n', '').strip()\n",
        "        d['review'] = review\n",
        "        return d\n",
        "\n",
        "    def load_data(self, filename, is_train=True):\n",
        "\n",
        "        raw_data = self._load_raw_data(filename, is_train)\n",
        "        lst = []\n",
        "\n",
        "        for row in raw_data:\n",
        "            lst.append(self._create_row(row, is_train))\n",
        "\n",
        "        return lst\n",
        "\n",
        "    def transform_to_dataset(self, x_set, y_set):\n",
        "        X, y = [], []\n",
        "        for document, topic in zip(list(x_set), list(y_set)):\n",
        "            document = normalize_text(document)\n",
        "            X.append(document.strip())\n",
        "            y.append(topic)\n",
        "            # Augmentation b·∫±ng c√°ch remove d·∫•u ti·∫øng Vi·ªát\n",
        "            X.append(no_marks(document))\n",
        "            y.append(topic)\n",
        "        return X, y"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIbCfi33zE6p"
      },
      "source": [
        "def return_data():\n",
        "    ds = DataSource()\n",
        "    train_data = pd.DataFrame(ds.load_data(\"/content/gdrive/MyDrive/sentiment_vietnamese/train.crash\"))\n",
        "    new_data = []\n",
        "    '''\n",
        "    # Th√™m m·∫´u b·∫±ng c√°ch l·∫•y trong t·ª´ ƒëi·ªÉn Sentiment (nag/pos)\n",
        "    nag_list, pos_list, not_list = diction_nag_pos_not()\n",
        "    for index, row in enumerate(pos_list):\n",
        "        new_data.append(['pos' + str(index), '0', row])\n",
        "    for index, row in enumerate(nag_list):\n",
        "        new_data.append(['nag' + str(index), '1', row])\n",
        "    '''\n",
        "    new_data = pd.DataFrame(new_data, columns=list(['id', 'label', 'review']))\n",
        "    train_data = train_data.append(new_data, ignore_index=True)\n",
        "    test_data = pd.DataFrame(ds.load_data('/content/gdrive/MyDrive/sentiment_vietnamese/test.crash', is_train=False))\n",
        "    return train_data, test_data"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyXNqgXYzUBE"
      },
      "source": [
        "train_data, test_data = return_data()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkfqD8M_z5Au"
      },
      "source": [
        "D·ªØ li·ªáu hu·∫•n luy·ªán"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zzoxzfX9zzLV",
        "outputId": "a6d5b613-555a-4c09-d1ef-f1562fba7c89"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_000000</td>\n",
              "      <td>0</td>\n",
              "      <td>\"Dung dc sp tot cam onshop ƒê√≥ng g√≥i s·∫£n ph·∫©m r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_000001</td>\n",
              "      <td>0</td>\n",
              "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi . Son m·ªãn nh∆∞n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_000002</td>\n",
              "      <td>0</td>\n",
              "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi nh∆∞ng k c√≥ h·ªôp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_000003</td>\n",
              "      <td>1</td>\n",
              "      <td>\":(( M√¨nh h∆°i th·∫•t v·ªçng 1 ch√∫t v√¨ m√¨nh ƒë√£ k·ª≥ v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_000004</td>\n",
              "      <td>1</td>\n",
              "      <td>\"L·∫ßn tr∆∞·ªõc m√¨nh mua √°o gi√≥ m√†u h·ªìng r·∫•t ok m√† ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16082</th>\n",
              "      <td>train_016082</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Ch·∫≥ng bi·∫øt l√† Shop c√≥ bi·∫øt ƒë·ªçc hay kh√¥ng mua ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16083</th>\n",
              "      <td>train_016083</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Cu·ªën n√†y m·ªèng. ƒê·ªçc m·ªôt bu·ªïi s√°ng l√† h·∫øt. Th√∫ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16084</th>\n",
              "      <td>train_016084</td>\n",
              "      <td>0</td>\n",
              "      <td>\"Mang √™m ch√¢n. ƒê·∫πp¬†\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16085</th>\n",
              "      <td>train_016085</td>\n",
              "      <td>1</td>\n",
              "      <td>\"T√¥i ƒë√£ nh·∫≠n ƒëc h√†ng.Sau ƒë√¢y l√† v√†i l·ªùi mu·ªën n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16086</th>\n",
              "      <td>train_016086</td>\n",
              "      <td>1</td>\n",
              "      <td>\"H√¨nh v·∫≠y m√† t√∫i x·∫•u q√° k√©m ch·∫•t lg q√°\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16087 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id label                                             review\n",
              "0      train_000000     0  \"Dung dc sp tot cam onshop ƒê√≥ng g√≥i s·∫£n ph·∫©m r...\n",
              "1      train_000001     0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi . Son m·ªãn nh∆∞n...\n",
              "2      train_000002     0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi nh∆∞ng k c√≥ h·ªôp...\n",
              "3      train_000003     1  \":(( M√¨nh h∆°i th·∫•t v·ªçng 1 ch√∫t v√¨ m√¨nh ƒë√£ k·ª≥ v...\n",
              "4      train_000004     1  \"L·∫ßn tr∆∞·ªõc m√¨nh mua √°o gi√≥ m√†u h·ªìng r·∫•t ok m√† ...\n",
              "...             ...   ...                                                ...\n",
              "16082  train_016082     1  \"Ch·∫≥ng bi·∫øt l√† Shop c√≥ bi·∫øt ƒë·ªçc hay kh√¥ng mua ...\n",
              "16083  train_016083     1  \"Cu·ªën n√†y m·ªèng. ƒê·ªçc m·ªôt bu·ªïi s√°ng l√† h·∫øt. Th√∫ ...\n",
              "16084  train_016084     0                               \"Mang √™m ch√¢n. ƒê·∫πp¬†\"\n",
              "16085  train_016085     1  \"T√¥i ƒë√£ nh·∫≠n ƒëc h√†ng.Sau ƒë√¢y l√† v√†i l·ªùi mu·ªën n...\n",
              "16086  train_016086     1            \"H√¨nh v·∫≠y m√† t√∫i x·∫•u q√° k√©m ch·∫•t lg q√°\"\n",
              "\n",
              "[16087 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6dSmpdsz8Rv"
      },
      "source": [
        "D·ªØ li·ªáu ki·ªÉm tra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "syUXQMipz-zq",
        "outputId": "9f6f5269-5433-486a-c3a2-53d331924509"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_000000</td>\n",
              "      <td>\"Ch∆∞a d√πng th·ª≠ n√™n ch∆∞a bi·∫øt\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_000001</td>\n",
              "      <td>\" Kh√¥ng ƒë√°ng ti·ªÅnV√¨ ngay ƒë·ª£t sale n√™n m·ªõi mua ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_000002</td>\n",
              "      <td>\"C√°m ∆°n shop. ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Ø...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_000003</td>\n",
              "      <td>\"V·∫£i ƒë·∫πp.phom oki lu√¥n.qu√° ∆∞ng\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_000004</td>\n",
              "      <td>\"Chu·∫©n h√†ng ƒë√≥ng g√≥i ƒë·∫πp\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10976</th>\n",
              "      <td>test_010976</td>\n",
              "      <td>\" Th·ªùi gian giao h√†ng r·∫•t nhanh.ngon.m√† cay qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10977</th>\n",
              "      <td>test_010977</td>\n",
              "      <td>\"S·∫£n ph·∫©m h∆°i c≈©\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10978</th>\n",
              "      <td>test_010978</td>\n",
              "      <td>\"S·∫£n ph·∫©m ch·∫Øc ch·∫Øn nh∆∞ng k b√≥ng b·∫±ng trong h√¨nh\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10979</th>\n",
              "      <td>test_010979</td>\n",
              "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi c√≥ m√πi th∆°m r·∫•...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10980</th>\n",
              "      <td>test_010980</td>\n",
              "      <td>\"nh∆∞ qu·∫£ng c√°o. sim r·∫•t t·ªët\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10981 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                id                                             review\n",
              "0      test_000000                      \"Ch∆∞a d√πng th·ª≠ n√™n ch∆∞a bi·∫øt\"\n",
              "1      test_000001  \" Kh√¥ng ƒë√°ng ti·ªÅnV√¨ ngay ƒë·ª£t sale n√™n m·ªõi mua ...\n",
              "2      test_000002  \"C√°m ∆°n shop. ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Ø...\n",
              "3      test_000003                    \"V·∫£i ƒë·∫πp.phom oki lu√¥n.qu√° ∆∞ng\"\n",
              "4      test_000004                          \"Chu·∫©n h√†ng ƒë√≥ng g√≥i ƒë·∫πp\"\n",
              "...            ...                                                ...\n",
              "10976  test_010976  \" Th·ªùi gian giao h√†ng r·∫•t nhanh.ngon.m√† cay qu...\n",
              "10977  test_010977                                  \"S·∫£n ph·∫©m h∆°i c≈©\"\n",
              "10978  test_010978  \"S·∫£n ph·∫©m ch·∫Øc ch·∫Øn nh∆∞ng k b√≥ng b·∫±ng trong h√¨nh\"\n",
              "10979  test_010979  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi c√≥ m√πi th∆°m r·∫•...\n",
              "10980  test_010980                       \"nh∆∞ qu·∫£ng c√°o. sim r·∫•t t·ªët\"\n",
              "\n",
              "[10981 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E-ZdJoH1A27"
      },
      "source": [
        "Kh·ªüi t·∫°o class DataSource ti·ªÅn x·ª≠ l√Ω t·∫≠p d·ªØ li·ªáu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knB9miuG0Xqm"
      },
      "source": [
        "ds = DataSource()\n",
        "X_train, y_train = ds.transform_to_dataset(train_data.review, train_data.label)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVUR-VAI1QoB",
        "outputId": "8f51a0ba-fa20-41a5-8b40-7c3ea6fcea67"
      },
      "source": [
        "print(\"T·∫≠p d·ªØ li·ªáu: \", X_train[0:5])\n",
        "print(\"K√≠ch th∆∞·ªõc t·∫≠p d·ªØ li·ªáu:\", len(X_train))\n",
        "print(\"T·∫≠p nh√£n:\", y_train[0:5])\n",
        "print(\"K√≠ch th∆∞·ªõc t·∫≠p nh√£n:\", len(y_train))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "T·∫≠p d·ªØ li·ªáu:  ['dung ƒë∆∞·ª£c s·∫£n ph·∫©m t·ªët cam on c·ª≠a h√†ng ƒë√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Øc ch·∫Øn ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi positive positive positive positive positive positive', 'dung duoc san pham tot cam on cua hang dong goi san pham rat dep va chac chan chat luong san pham tuyet voi positive positive positive positive positive positive', 'ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi son m·ªãn nh∆∞ng khi ƒë√°nh l√™n kh√¥ng nh∆∞ m√†u tr√™n ·∫£nh positive positive positive', 'chat luong san pham tuyet voi son min nhung khi danh len khong nhu mau tren anh positive positive positive', 'ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi nh∆∞ng kh√¥ng c√≥ h·ªôp kh√¥ng c√≥ d√¢y gi√†y ƒëen kh√¥ng c√≥ t·∫•t positive positive']\n",
            "K√≠ch th∆∞·ªõc t·∫≠p d·ªØ li·ªáu: 32174\n",
            "T·∫≠p nh√£n: [0, 0, 0, 0, 0]\n",
            "K√≠ch th∆∞·ªõc t·∫≠p nh√£n: 32174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rkUD58a16P2"
      },
      "source": [
        "Chia t·∫≠p d·ªØ li·ªáu ban ƒë·∫ßu th√†nh 2 ph·∫ßn X_train, y_train v√† X_test, y_test theo t·ªâ l·ªá 3:1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chd-Y0Nm2GaH",
        "outputId": "177829fb-bae8-465b-8bf8-2057e7aa7e31"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3,\n",
        "                                                        random_state=42)\n",
        "x_train, x_test = np.asarray(x_train), np.asarray(x_test)\n",
        "y_train, y_test = np.asarray(y_train), np.asarray(y_test)\n",
        "print(\"S·ªë l∆∞·ª£ng d·ªØ li·ªáu hu·∫•n luy·ªán {}\".format(x_train.shape))\n",
        "print(\"S·ªë l∆∞·ª£ng d·ªØ li·ªáu ki·ªÉm tra {}\".format(x_test.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S·ªë l∆∞·ª£ng d·ªØ li·ªáu hu·∫•n luy·ªán (22521,)\n",
            "S·ªë l∆∞·ª£ng d·ªØ li·ªáu ki·ªÉm tra (9653,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbp42E2P3w6R"
      },
      "source": [
        "Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng nh√£n t√≠ch c·ª±c nh√£n 0 v√† s·ªë l∆∞·ª£ng nh√£n ti√™u c·ª±c nh√£n 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOs3n8723xyU",
        "outputId": "d9f813fb-259e-47c1-e3fb-c081e12ca7f2"
      },
      "source": [
        "np.unique(y_train, return_counts= True)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([13004,  9517]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zSVkyO5432mY",
        "outputId": "eb798e60-7078-4fb8-cd82-90ca2977191c"
      },
      "source": [
        "dd = pd.Series(y_train).value_counts()\n",
        "sns.barplot(x=np.array(['positive','negative']),y=dd.values)\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cilddjmX4dGS"
      },
      "source": [
        "Tokenize d·ªØ li·ªáu: ƒë∆∞a ra t·∫≠p t·ª´ ƒëi·ªÉn, idex c·ªßa m·ªôt c√¢u trong t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán v√† t·∫≠p d·ªØ li·ªáu ki·ªÉm tra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWhyFd7D4DPD"
      },
      "source": [
        "def preprocess_string(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with no space\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # replace digits with no space\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRDQa1Hk5HDD",
        "outputId": "52c9a11c-def4-4128-90af-d760b5d9837f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop = set(stopwords.words('english'))\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7-YgMuu5K1C"
      },
      "source": [
        "def tockenize(x_train,y_train,x_val,y_val):\n",
        "    word_list = []\n",
        "\n",
        "    stop_words = stop\n",
        "    for sent in x_train:\n",
        "        for word in sent.lower().split():\n",
        "            word = preprocess_string(word)\n",
        "            if word not in stop_words and word != '':\n",
        "                word_list.append(word)\n",
        "  \n",
        "    corpus = Counter(word_list)\n",
        "    # sorting on the basis of most common words\n",
        "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
        "    # creating a dict\n",
        "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
        "    \n",
        "    # tockenize\n",
        "    final_list_train,final_list_test = [],[]\n",
        "    for sent in x_train:\n",
        "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
        "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
        "    for sent in x_val:\n",
        "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
        "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
        "            \n",
        "    # encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n",
        "    # encoded_test = [1 if label =='positive' else 0 for label in y_val] \n",
        "    encoded_train = y_train\n",
        "    encoded_test = y_val\n",
        "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juXqqT6V5PdX",
        "outputId": "33c01a51-33aa-4226-fdd4-50642f7397f7"
      },
      "source": [
        "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IpMMIbWe6dP",
        "outputId": "ae62559c-7283-43e1-e631-5bb88db579f8"
      },
      "source": [
        "print(x_train)\n",
        "print(y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[list([157, 427, 116, 86, 386, 84, 220, 157, 116, 86, 230, 12, 3, 2])\n",
            " list([170, 24, 27, 572, 73, 31, 7, 4, 20, 191, 174, 50, 53, 134, 325, 563, 179, 168, 1, 1])\n",
            " list([81, 16, 536, 58, 318, 282, 40, 520, 12, 3, 86, 115, 438, 40, 12, 3, 15, 121, 139, 193, 446, 39, 2, 2])\n",
            " ...\n",
            " list([7, 4, 20, 513, 28, 665, 4, 497, 497, 190, 195, 558, 314, 188, 54, 124, 122, 64, 150, 134, 77, 671, 252, 118, 422, 72, 134, 325, 563, 16, 96, 13, 4, 88, 84, 1])\n",
            " list([12, 3, 66, 31, 116, 120, 89, 41, 99, 212, 43, 7, 89, 41, 86, 89, 67, 114, 87, 107, 113, 15, 121, 139, 66, 153, 423, 114, 12, 12, 3, 189, 1])\n",
            " list([7, 18, 374, 94, 4])]\n",
            "[0 0 1 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxGrPcvJ5Yv0"
      },
      "source": [
        "## M√£ ho√° d·ªØ li·ªáu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ky_QyDd5c9y",
        "outputId": "34ead871-ae49-48f9-9f52-8f7f38be755f"
      },
      "source": [
        "print(len(x_train))\n",
        "print(\"Hi·ªÉn th·ªã d·ªØ li·ªáu hu·∫•n luy·ªán sau khi m√£ ho√°:\", x_train[0:5])\n",
        "print(len(y_train))\n",
        "y_train\n",
        "print(vocab)\n",
        "print(\"K√≠ch th∆∞·ªõc c·ªßa t·ª´ ƒëi·ªÉn:\",len(vocab))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22521\n",
            "Hi·ªÉn th·ªã d·ªØ li·ªáu hu·∫•n luy·ªán sau khi m√£ ho√°: [list([157, 427, 116, 86, 386, 84, 220, 157, 116, 86, 230, 12, 3, 2])\n",
            " list([170, 24, 27, 572, 73, 31, 7, 4, 20, 191, 174, 50, 53, 134, 325, 563, 179, 168, 1, 1])\n",
            " list([81, 16, 536, 58, 318, 282, 40, 520, 12, 3, 86, 115, 438, 40, 12, 3, 15, 121, 139, 193, 446, 39, 2, 2])\n",
            " list([263, 803, 46, 321, 71, 14, 31, 63, 500, 63, 803, 972, 131, 573, 334, 487, 49, 343, 352, 487, 803, 134, 574, 630, 295, 174, 487, 122, 18, 487, 803, 14, 105, 505, 209, 192, 283, 11, 10, 102, 38, 94, 582, 91, 487, 172, 209, 192, 2, 2, 2, 2])\n",
            " list([38, 16, 36, 90, 655, 527, 91, 439, 4, 14, 191, 140, 19, 22, 11, 10, 6, 118, 13, 4, 79, 74, 6, 2, 2, 1])]\n",
            "22521\n",
            "{'positive': 1, 'nagative': 2, 'hang': 3, 'h√†ng': 4, 'rat': 5, 'r·∫•t': 6, 'giao': 7, 'pham': 8, 'san': 9, 'ph·∫©m': 10, 's·∫£n': 11, 'cua': 12, 'c·ª≠a': 13, 'kh√¥ng': 14, 'khong': 15, 'mua': 16, 'chat': 17, 'notpos': 18, 'ch·∫•t': 19, 'nhanh': 20, 'luong': 21, 'l∆∞·ª£ng': 22, 'dep': 23, 'ƒë·∫πp': 24, 'co': 25, 'va': 26, 'v√†': 27, 'goi': 28, 'dong': 29, 'voi': 30, 'gian': 31, 'cho': 32, 'g√≥i': 33, 'dung': 34, 'minh': 35, 'c√≥': 36, 'ƒë√≥ng': 37, 'm√¨nh': 38, 'qua': 39, 'nhung': 40, 'la': 41, 'chan': 42, 'thi': 43, 'tuy·ªát': 44, 'tuyet': 45, 'ch·∫Øc': 46, 'chac': 47, 'tien': 48, 'th√¨': 49, 'l√†': 50, 'tot': 51, 'duoc': 52, 't·ªët': 53, 'nh∆∞ng': 54, 'v·ªùi': 55, 'dang': 56, 'ti·ªÅn': 57, 'da': 58, 'thoi': 59, 'nhu': 60, 'ch·∫Øn': 61, 'ƒë∆∞·ª£c': 62, 'm√†': 63, 'ok': 64, 'bi': 65, 'lam': 66, 'nhan': 67, 'khi': 68, 'mau': 69, 'ƒë√°ng': 70, 'qu√°': 71, 'ra': 72, 'th·ªùi': 73, 'v·ª•': 74, 'cung': 75, 'kem': 76, 'nh∆∞': 77, 'nay': 78, 'ph·ª•c': 79, 'vu': 80, 'moi': 81, 'phuc': 82, 'gia': 83, 'lai': 84, 'con': 85, 'de': 86, 'hoi': 87, 'trong': 88, 'ban': 89, 'b·ªã': 90, 'l·∫°i': 91, 'nen': 92, 'thay': 93, 'ƒë√£': 94, 'ho': 95, 'c·ªßa': 96, 'v·ªõi': 97, 'sao': 98, 'cam': 99, 'sau': 100, 'gi√°': 101, 'n√†y': 102, 'd√πng': 103, 'ung': 104, 'n√™n': 105, 'hinh': 106, 'may': 107, 'van': 108, 'noi': 109, 'm√†u': 110, 'cai': 111, 'k√©m': 112, 'lan': 113, 'tin': 114, 'bao': 115, 'doi': 116, 'chi': 117, 'notnag': 118, 'se': 119, 'dat': 120, 'tra': 121, 'c≈©ng': 122, 'giay': 123, 'th·∫•y': 124, 'dau': 125, 'su': 126, 'nh·∫≠n': 127, 'star': 128, 'roi': 129, 'gi': 130, 'h√¨nh': 131, 'l·∫ßn': 132, 'hay': 133, 's·∫Ω': 134, 'day': 135, 'l·∫Øm': 136, 'c√°i': 137, 'ngon': 138, 'loi': 139, 'g√¨': 140, 'h∆°i': 141, 'hon': 142, 'nua': 143, 'nhieu': 144, 'm·ªõi': 145, 'toi': 146, 'tinh': 147, 'r·ªìi': 148, 'phai': 149, 'mong': 150, 'c√≤n': 151, 'h∆°n': 152, 'mat': 153, 'chua': 154, 'nhi·ªÅu': 155, 'n·ªØa': 156, 'em': 157, 'v·ªÅ': 158, 'luon': 159, 'k': 160, 'ngay': 161, 'chu': 162, 'tu': 163, 'ƒë·∫∑t': 164, 'hop': 165, 'ph·∫£i': 166, 'nao': 167, 'h·ªô': 168, 'di': 169, 'gi√†y': 170, 'son': 171, 'ƒë·ªÉ': 172, 'biet': 173, 'chung': 174, 'vi': 175, 'ch·ªâ': 176, 'lu√¥n': 177, 'sach': 178, '·ªßng': 179, 'den': 180, 'tiki': 181, 'ca': 182, 'l√†m': 183, 'dai': 184, 'tr·∫£': 185, 'het': 186, 'nha': 187, 'n√†o': 188, 'e': 189, 'ch∆∞a': 190, 'n√≥i': 191, 'd·ª•ng': 192, 'giong': 193, 'hai': 194, 'bi·∫øt': 195, 's√°ch': 196, 'thu': 197, 'c·∫£m': 198, 'ƒëi': 199, 'long': 200, 'vay': 201, 'c·∫£': 202, 'nhe': 203, 'len': 204, 'tam': 205, 'v·∫´n': 206, 'h·∫øt': 207, '∆°n': 208, 's·ª≠': 209, 'c·ª°': 210, 'ƒÉn': 211, 'tay': 212, 't√¨nh': 213, 'du': 214, 'v√¨': 215, 'mang': 216, 'pin': 217, 'vong': 218, 'vua': 219, 'gui': 220, 'd√†i': 221, 'cao': 222, 'vao': 223, 'm·ªôt': 224, 'l√™n': 225, 'gi·ªëng': 226, 'mot': 227, 'v·∫≠y': 228, '·∫°': 229, 'trang': 230, 'v√†o': 231, 'nho': 232, 'v·ª´a': 233, 'khac': 234, 'lau': 235, 'thich': 236, 'ƒë·∫ßu': 237, 'bo': 238, 't√¥i': 239, 'sac': 240, 'th√≠ch': 241, 'xem': 242, 'ben': 243, 'ng√†y': 244, 'anh': 245, 'thuong': 246, 'cham': 247, 'nguoi': 248, 'kha': 249, 'ng∆∞·ªùi': 250, 'mui': 251, 'v·ªçng': 252, 'nghe': 253, '√Ω': 254, 'b√°n': 255, 'yeu': 256, 'luc': 257, 'xai': 258, 'm√°y': 259, 'b·∫°n': 260, 'mo': 261, 'l·ªùi': 262, 'kh√°': 263, 'g·ª≠i': 264, 'kho': 265, 'd·ªÖ': 266, 'kh√°c': 267, 'dan': 268, 'phan': 269, 'khach': 270, 'vo': 271, 'cu': 272, 'ƒë√∫ng': 273, 'ng': 274, 'tang': 275, 'te': 276, 'x√†i': 277, 'ai': 278, 'kh√°ch': 279, 'cac': 280, 'nhi·ªát': 281, 'sai': 282, '·ªü': 283, 'cuc': 284, 'nhiet': 285, 'nhin': 286, 'tuy': 287, 'ƒë·∫øn': 288, 'xong': 289, 'l√¢u': 290, 'ƒë·ªïi': 291, 'h·ªôp': 292, 'ta': 293, 'thieu': 294, 'nh√¨n': 295, 'th·∫•t': 296, 'ch·∫≠m': 297, 'y√™u': 298, 'r·∫ª': 299, 'danh': 300, 'chuyen': 301, 'tren': 302, 'c√°c': 303, 't·∫∑ng': 304, 'vai': 305, 'tiep': 306, 'm√πi': 307, 'doc': 308, 'b√™n': 309, 'th·∫≠t': 310, 'ƒë·ªçc': 311, 'l√∫c': 312, '∆∞ng': 313, 'th·∫ø': 314, 'h·ª£p': 315, 'l√≤ng': 316, 'nh√©': 317, 'chay': 318, 't·ª´': 319, 'quan': 320, 'nh·ªè': 321, 'th√™m': 322, 'b·∫£o': 323, 'l·ªói': 324, 'ti·∫øp': 325, 'cau': 326, 'keo': 327, 'dien': 328, 'xinh': 329, 'm·∫∑t': 330, 'nh·∫Øn': 331, 'tr√™n': 332, 'gio': 333, 'theo': 334, 'han': 335, 'ƒë√≥': 336, 'sang': 337, 'c·∫©n': 338, 'dinh': 339, 'b√©': 340, 'nhat': 341, 'th√¥i': 342, 'm·∫•t': 343, 'th·∫≠n': 344, 'hong': 345, 'n√≥': 346, 'ch√¢n': 347, 'ngoai': 348, 'tuong': 349, 'chinh': 350, 'ƒë·ªìng': 351, 'ƒë·ªô': 352, 'h√†i': 353, 'ki': 354, 'nh·ªØng': 355, 's·∫°c': 356, '·∫£nh': 357, 'th·ªÉ': 358, 'mac': 359, 'thanh': 360, 'truoc': 361, 'h': 362, 'c√°m': 363, 'tai': 364, 'thi·∫øu': 365, 'm·∫•y': 366, 'ghi': 367, 'tr∆∞·ªõc': 368, 'chu·∫©n': 369, 't·ªá': 370, 'binh': 371, 'qu·∫£': 372, 'chuan': 373, 'm·∫´u': 374, 'neu': 375, 'thom': 376, 'loai': 377, 'c·ª±c': 378, 'muon': 379, 'cong': 380, 'gi·ªù': 381, 'hieu': 382, 'n·∫øu': 383, 's·ª±': 384, 'ch√≠nh': 385, 'xanh': 386, 'kinh': 387, 'nhau': 388, 'ƒë√¢y': 389, 'v·∫•n': 390, 'ƒë√¥i': 391, 'd√π': 392, 'th∆°m': 393, 'nghi': 394, 'ky': 395, 'sieu': 396, 'nuoc': 397, 'ƒëi·ªán': 398, 'deu': 399, 'ƒë√°nh': 400, 'ngo√†i': 401, 'cach': 402, 'ƒë·ªì': 403, 's·ªë': 404, 'mai': 405, 'n∆∞·ªõc': 406, 'trung': 407, 'd√¢y': 408, 'toan': 409, 'b√¨nh': 410, 'dao': 411, 'bat': 412, 'ch·ª©': 413, 'tham': 414, 'mu·ªën': 415, 'lo·∫°i': 416, '·ªïn': 417, 'mem': 418, 'si√™u': 419, 'h·ªì': 420, 'nhi√™n': 421, 'bong': 422, 'uy': 423, 'c√°ch': 424, 'ao': 425, 'g·ªçi': 426, 'lay': 427, 'm·ªèng': 428, 'th∆∞∆°ng': 429, 'th·ª≠': 430, 'chai': 431, 'duong': 432, 'th·ª©': 433, 'th∆∞·ªùng': 434, 'thuc': 435, 'cu·ªën': 436, 'bang': 437, 'hanh': 438, 'ch·ªß': 439, 'm·ªÅm': 440, 'nam': 441, 'hom': 442, 'ƒë√¢u': 443, 'xau': 444, 'dam': 445, 'lua': 446, 'ph·∫ßn': 447, 'ch·ªãu': 448, 'chuy·ªÉn': 449, 'tui': 450, 'cuon': 451, 'chiu': 452, 'cay': 453, 'x·∫•u': 454, 'kieu': 455, '√™m': 456, 'gi·∫£': 457, 'nh√†': 458, 'ƒë·ªÅu': 459, 'm·∫∑c': 460, 'nh·∫•t': 461, 'ki·ªÉu': 462, 'm·ªü': 463, 'tac': 464, 'nh√¢n': 465, 'man': 466, 'nhien': 467, 'kiem': 468, 'kh√≥': 469, 'thang': 470, 'l·∫•y': 471, 'che': 472, 'lo': 473, 'hu': 474, 't∆∞': 475, 'h√£ng': 476, 'ch√∫t': 477, 'to√†n': 478, 't√°c': 479, 'hoan': 480, 'c': 481, 't√¢m': 482, 'h·ªèi': 483, 'nham': 484, 'ƒë∆°n': 485, 'ho√†n': 486, 'g': 487, 'ti': 488, 'boc': 489, 'h√†nh': 490, 'c√πng': 491, 'hoa': 492, 'h√¥m': 493, 'c·ª©': 494, 'ko': 495, 'chut': 496, 't·∫°m': 497, 'sim': 498, 'chang': 499, 'xa': 500, 'chon': 501, 'tan': 502, 'dieu': 503, 'ch·∫°y': 504, 'ƒë·ª£i': 505, 'ro': 506, 'h·∫°n': 507, 's√°ng': 508, 'huong': 509, '√°o': 510, 'm·ªói': 511, 'm·ªçi': 512, 'ƒë·ªß': 513, 'ch√°n': 514, 't∆∞·ªüng': 515, 'nang': 516, 'ƒëi·ªÅu': 517, '√≠t': 518, 'ke': 519, 'lien': 520, 'm√£': 521, 'tuc': 522, 'v·∫£i': 523, 'lun': 524, 'tem': 525, 'min': 526, 'b√°o': 527, 'le': 528, 'sua': 529, 'phu': 530, 'gan': 531, 'thoai': 532, 'c≈©': 533, 'c·∫ßn': 534, 'b·ªô': 535, 'deo': 536, 'kh√¥': 537, 'ƒëang': 538, 't·ªõi': 539, 'c√°o': 540, 'toc': 541, 'oi': 542, 'gay': 543, 'b·ªè': 544, 'phong': 545, 'banh': 546, 'ly': 547, 'phi': 548, 'mieng': 549, 'qu√†': 550, 'th√†nh': 551, 'lon': 552, 'cap': 553, 'ƒëen': 554, 'viet': 555, 'check': 556, 'm·ªãn': 557, 'd√°n': 558, 't√∫i': 559, 'ch·ªçn': 560, 'v√¥': 561, 'meo': 562, 't·ª•c': 563, 'ki·ªÉm': 564, 'th·ª±c': 565, 'thong': 566, 't·∫£': 567, 'b·∫±ng': 568, 'c·ª©ng': 569, 'c√¥ng': 570, 'b√°nh': 571, 'nh·∫π': 572, 'k√®m': 573, 't·ª±': 574, 'b': 575, 'rong': 576, 'tat': 577, 'chuc': 578, 't√≠nh': 579, 'mop': 580, 'coi': 581, 'quay': 582, 'tieng': 583, 'gi·∫•y': 584, 'quyen': 585, 'truy·ªán': 586, 'd√≠nh': 587, 'hi·ªÉu': 588, 'th√°ng': 589, 'chong': 590, 'ƒë·ªÅ': 591, 'truyen': 592, 'vui': 593, 'l·ª´a': 594, 'iphone': 595, 'ƒë·ªãnh': 596, 'kƒ©': 597, 'n': 598, 'tuan': 599, 'vien': 600, 'nghƒ©': 601, 'xin': 602, 'n·ªôi': 603, 'nh·∫ßm': 604, 'c·∫ßu': 605, 'xe': 606, 'r√µ': 607, 'buon': 608, 'sinh': 609, 'h·ªìi': 610, 'thiet': 611, 'phim': 612, 'nap': 613, 'ket': 614, 'kim': 615, 'c√¢u': 616, 'bay': 617, 'mi·∫øng': 618, 'ƒëi·ªÉm': 619, 'k·ªπ': 620, 'm√¥i': 621, 'l√Ω': 622, 'trc': 623, 'bung': 624, 'nong': 625, 'tim': 626, 'giac': 627, 'v·∫≠n': 628, 'h·ªèng': 629, 'k·∫øt': 630, 'th√¥ng': 631, 'd·∫ßu': 632, 'li√™n': 633, 'op': 634, 'quy·ªÉn': 635, 'tu·∫ßn': 636, 'b·∫£n': 637, 't√≠n': 638, 'rach': 639, 'lieu': 640, 'giam': 641, 'quat': 642, 'viec': 643, 'chuot': 644, 'li·ªáu': 645, 's·ªØa': 646, 'gi√°c': 647, 'diem': 648, 'h·ªìng': 649, 'uong': 650, 'ch·ªó': 651, 'cha': 652, 'nhua': 653, 'r·ªông': 654, 'r√°ch': 655, 'hien': 656, 'm√≥p': 657, 'ba': 658, 'nut': 659, 'vi·ªác': 660, 'chap': 661, 'bia': 662, 'hi': 663, 'troi': 664, 'b·ªçc': 665, 'ƒë·ªè': 666, 'tung': 667, 'lap': 668, 'h∆∞': 669, 'ngan': 670, 'k√¨': 671, 'ph√≠': 672, 'tro': 673, 'sale': 674, 'song': 675, 'mk': 676, 'nh·ª±a': 677, 'rang': 678, 'd√†y': 679, 'v√†i': 680, 'loa': 681, 'dich': 682, 'tr·∫Øng': 683, 't·∫°i': 684, 'bim': 685, 'xay': 686, 'ti·∫øng': 687, 'mi': 688, 'ch·ªã': 689, 'ti√™n': 690, 'dua': 691, 'tho·∫°i': 692, 't√≠': 693, 'ƒë∆∞·ªùng': 694, 'dem': 695, 'trai': 696, 'cang': 697, 'test': 698, 'nguyen': 699, 'phat': 700, 'hi·ªán': 701, 'qu·∫ßn': 702, 'gi·∫ßy': 703, '∆°i': 704, 'd·ªãch': 705, 'b·∫Øt': 706, 'b√†n': 707, 'ch·∫≥ng': 708, 'xuat': 709, 'v': 710, 'giai': 711, 'hat': 712, 'ph√π': 713, 'ph·∫£n': 714, 'hi·ªáu': 715, 'm√©o': 716, 'ip': 717, 'n·∫Øp': 718, 'm√¥': 719, 'ƒëeo': 720, 'gi·∫£i': 721, 'c·∫Øm': 722, 'n·ªïi': 723, '·ªëp': 724, 'thai': 725, 'chup': 726, 'xiu': 727, 'vang': 728, 'ƒë·ª´ng': 729, 'b·ªÅn': 730, 'tre': 731, 'kia': 732, 'gi·∫£m': 733, 's·∫Øc': 734, 'muc': 735, 'vi√™n': 736, 'hut': 737, 'm·∫Øt': 738, 'xu·∫•t': 739, 'thi·∫øt': 740, 'nau': 741, 'quy·∫øt': 742, 'n√≥ng': 743, 'm√£i': 744, 'd√©p': 745, 'v·ªã': 746, 'ƒë·ªông': 747, 'v·ª°': 748, 'qu·∫°t': 749, 'l': 750, 'ch·ªù': 751, 'ah': 752, 'khuyen': 753, 'quyet': 754, 'ph√°t': 755, 't∆∞·ª£ng': 756, 'th√¢n': 757, 'vi·∫øt': 758, 'gioi': 759, 'lem': 760, 'mon': 761, 'v·ªè': 762, 'form': 763, 't·∫•t': 764, 'k√≠nh': 765, 'ch·ª•p': 766, 'keu': 767, 'hoc': 768, 'chuy·ªán': 769, 'manh': 770, 'ƒë·∫ßy': 771, 'li': 772, 'ngo': 773, 'ga': 774, 'b√¨a': 775, 'ƒë·∫£o': 776, 'vat': 777, 'x√≠u': 778, 'kien': 779, 'ay': 780, 'th√°i': 781, 'tiec': 782, 'cuoi': 783, 'nh': 784, 't·ªôi': 785, 'dap': 786, 'u·ªëng': 787, 'boi': 788, 'ch·∫£': 789, 'mun': 790, 'nguy√™n': 791, '·∫•y': 792, 't·∫≠n': 793, 'bam': 794, 'p': 795, 'thua': 796, 'ƒë√®n': 797, 'c√¢n': 798, 'chu·ªôt': 799, 'mn': 800, 'g·∫ßn': 801, 'ph√≠m': 802, 'y·∫øu': 803, 'lum': 804, 'd√°m': 805, 'tap': 806, 'ntn': 807, 'h·ªá': 808, 'ƒë·∫ø': 809, 'tiet': 810, 'h√∫t': 811, 'kich': 812, 'ham': 813, 'c√†ng': 814, 'ƒë·∫Øt': 815, 'h·∫°t': 816, 't√≥c': 817, 'm√†n': 818, 'h·ªçc': 819, 'm·ª•n': 820, 'l·ªõn': 821, 'gap': 822, 'ch·ªëng': 823, 'bot': 824, 'dac': 825, 'choi': 826, 'combo': 827, 'dt': 828, 'buc': 829, 'r·ª≠a': 830, 'ƒë·∫•y': 831, 'd·∫´n': 832, 'vƒÉn': 833, 'ty': 834, 'ghe': 835, 'com': 836, 't·ª´ng': 837, 'ch·∫•p': 838, 'shiper': 839, 'wifi': 840, 'k√™u': 841, 'c·ª•c': 842, 'c√¢y': 843, 'th·∫•m': 844, 'ti·∫øt': 845, 'tao': 846, 'dot': 847, 'xuoc': 848, 'quen': 849, 'ch·ªØ': 850, 'khoi': 851, 'ƒëƒÉng': 852, 'ng·ªçt': 853, 'm√°t': 854, 'tray': 855, 'c∆°': 856, 'sony': 857, 'ong': 858, 'lung': 859, 'canh': 860, 'review': 861, 'tr·ª£': 862, 'l·∫Ω': 863, 'ch√∫c': 864, 'gb': 865, 'lot': 866, 'hoac': 867, 'goc': 868, 'moc': 869, 'led': 870, 'n√∫t': 871, 't·∫≠p': 872, 'ƒë·∫∑c': 873, 'xung': 874, 't·∫ßm': 875, 'lop': 876, 'x∆∞·ªõc': 877, 'ngot': 878, 'l·∫Øp': 879, 'b·ªâm': 880, 'bu·ªìn': 881, 'l·ªõp': 882, '·∫•n': 883, 'bu': 884, 'ti·∫øc': 885, 'hag': 886, 'na': 887, 'h∆∞·ªõng': 888, 'b√¨': 889, 'hk': 890, 'khen': 891, 'ƒëau': 892, 'ngu': 893, 't·ªëc': 894, 's∆°': 895, 'v·∫ª': 896, 'cat': 897, 'v√†ng': 898, 'suy': 899, 'thien': 900, 'chieu': 901, 'nƒÉm': 902, 'ki·∫øn': 903, 'samsung': 904, 'rua': 905, 'r': 906, 'ha': 907, 's·∫°ch': 908, 'bit': 909, 'm·∫°ng': 910, 'nhac': 911, 'khau': 912, 't·∫ø': 913, 'nƒÉng': 914, 'trach': 915, 'th√®m': 916, 'duoi': 917, 'b·∫•t': 918, 'hy': 919, 'k·ª≥': 920, 'tranh': 921, 'cu·ªëi': 922, 'treo': 923, 'ƒët': 924, 'h·ªÅ': 925, 'h·ªó': 926, 'sh': 927, 'nhug': 928, 'tron': 929, 'mask': 930, 'ƒë·ª±ng': 931, 'z': 932, 'x': 933, 'g√£y': 934, 'truong': 935, 'd∆∞·ª°ng': 936, 'gon': 937, 'xet': 938, 'luu': 939, 'd√≤ng': 940, 'quoc': 941, 'tr·∫ßy': 942, 'c√¥': 943, 'chi·∫øc': 944, 'l·ªèng': 945, 'soc': 946, 'ti·ªán': 947, 'gion': 948, 'tr√°ch': 949, 'chiec': 950, 'c·ªë': 951, 'k·∫ø': 952, 'm√≥n': 953, 'ƒë∆∞a': 954, 'v·∫≠t': 955, 'g√†': 956, 't·ªëi': 957, 'k√≠ch': 958, 'c·∫ßm': 959, 'ch√°y': 960, 'troc': 961, 'nh·∫°t': 962, 's·ª£': 963, 'hao': 964, 'nguon': 965, 'xu': 966, 'ƒë·ªëi': 967, 'ton': 968, 'rung': 969, 'ne': 970, 'ho·∫∑c': 971, 'h·∫≥n': 972, 'ng·ªù': 973, 'giat': 974, 'tr√≥c': 975, 'n·ªìi': 976, 'khoa': 977, 'l·ª±c': 978, '√†': 979, 'b·∫©n': 980, 'g√¢y': 981, 'cm': 982, 'l√≥t': 983, 'muot': 984, 'nhiem': 985, 'ch∆°i': 986, '·ª©ng': 987, 'khan': 988, 'khung': 989, 'gi·ªõi': 990, 'quai': 991, 'd·ª±': 992, 'haiz': 993, 'im': 994, 'ch√™': 995, 'bac': 996, 'm·∫°nh': 997, 'tru': 998, 'nhi·ªám': 999, 'd·∫∑n': 1000}\n",
            "K√≠ch th∆∞·ªõc c·ªßa t·ª´ ƒëi·ªÉn: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWueUg7454GY"
      },
      "source": [
        "Th·ªëng k√™ ƒë·ªô d√†i trung b√¨nh c·ªßa m·ªôt b√¨nh lu·∫≠n: 20 t·ª´"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "IUH99zWh56o0",
        "outputId": "f694e09b-6de3-4da0-ecb1-061874c74b8b"
      },
      "source": [
        "rev_len = [len(i) for i in x_train]\n",
        "pd.Series(rev_len).hist()\n",
        "plt.show()\n",
        "pd.Series(rev_len).describe()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    22521.000000\n",
              "mean        20.925758\n",
              "std         20.516213\n",
              "min          0.000000\n",
              "25%          9.000000\n",
              "50%         16.000000\n",
              "75%         26.000000\n",
              "max        556.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EhLHNEc6a2N"
      },
      "source": [
        "Qu√° tr√¨nh Padding - ch√®n t·ª´ng chu·ªói ƒë·ªÉ t·ª´ng chu·ªói c√≥ ƒë·ªô d√†i t·ªëi ƒëa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-1Wf4Ul6Vei"
      },
      "source": [
        "def padding_(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJULg8TZ6e6R",
        "outputId": "7758efcb-d50d-4db6-fe9d-e78b2c9fb1ac"
      },
      "source": [
        "x_train_pad = padding_(x_train,100)\n",
        "x_test_pad = padding_(x_test,100)\n",
        "print(x_train_pad[0:5])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0 157 427 116  86\n",
            "  386  84 220 157 116  86 230  12   3   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0 170  24  27 572  73  31   7   4  20 191\n",
            "  174  50  53 134 325 563 179 168   1   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  81  16 536  58 318 282  40 520  12   3  86 115 438  40\n",
            "   12   3  15 121 139 193 446  39   2   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0 263 803  46 321  71  14\n",
            "   31  63 500  63 803 972 131 573 334 487  49 343 352 487 803 134 574 630\n",
            "  295 174 487 122  18 487 803  14 105 505 209 192 283  11  10 102  38  94\n",
            "  582  91 487 172 209 192   2   2   2   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  38  16  36  90 655 527  91 439   4  14 191 140  19  22  11  10\n",
            "    6 118  13   4  79  74   6   2   2   1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDTExJ4e6v8u"
      },
      "source": [
        "T·∫£i v√† chuy·ªÉn d·ªØ li·ªáu d∆∞·ªõi d·∫°ng Tensor Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9i9K_IU6xRW"
      },
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
        "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFg0zkUd68rB"
      },
      "source": [
        "## X√¢y d·ª±ng m√¥ h√¨nh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_t2Dnq_67r0"
      },
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "  def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n",
        "        super(SentimentRNN,self).__init__()\n",
        " \n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        " \n",
        "        self.no_layers = no_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        #lstm\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
        "                           num_layers=no_layers, batch_first=True)\n",
        "        \n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "    \n",
        "        # linear and sigmoid layer\n",
        "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "  def forward(self,x,hidden):\n",
        "        batch_size = x.size(0)\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
        "        # print(\"Embedim_shape:\",embeds.shape)  #[50, 500, 1000]\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        \n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n",
        "        \n",
        "        # dropout and fully connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "  def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        hidden = (h0,c0)\n",
        "        return hidden"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6NjS8Uq7MMs",
        "outputId": "2b1d071c-88fc-4eb7-e6c5-a9f651e71adc"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "no_layers = 2\n",
        "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
        "\n",
        "embedding_dim = 64\n",
        "output_dim = 1\n",
        "hidden_dim = 256\n",
        "\n",
        "\n",
        "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n",
        "\n",
        "#moving to gpu\n",
        "model.to(device)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(1001, 64)\n",
            "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZmNRyrS7gDV"
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# function to predict accuracy\n",
        "def acc(pred,label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTNsm5V-7mqu",
        "outputId": "525f6d60-7e2c-4728-db0a-2770b2f25058"
      },
      "source": [
        "clip = 5\n",
        "epochs = 10\n",
        "valid_loss_min = np.Inf\n",
        "# train for some number of epochs\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    # initialize hidden state \n",
        "    h = model.init_hidden(batch_size)\n",
        "    for inputs, labels in train_loader:\n",
        "        \n",
        "        inputs, labels = inputs.to(device), labels.to(device) \n",
        "        # print(\"inputs:\", inputs)\n",
        "        # print(\"inputs shape:\", inputs.shape)\n",
        "        # print(\"labels:\", labels)\n",
        "        # print(\"labels shape:\", labels.shape)\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "        # print(\"h:\", h)\n",
        "        # print(\"h shape:\", len(h))\n",
        "        model.zero_grad()\n",
        "        output,h = model(inputs,h)\n",
        "        \n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "        # calculating accuracy\n",
        "        accuracy = acc(output,labels)\n",
        "        train_acc += accuracy\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "    \n",
        "        \n",
        "    val_h = model.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "    for inputs, labels in valid_loader:\n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "            val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "            val_losses.append(val_loss.item())\n",
        "            \n",
        "            accuracy = acc(output,labels)\n",
        "            val_acc += accuracy\n",
        "            \n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}') \n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/sentiment_vietnamese/state_dict.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
        "        valid_loss_min = epoch_val_loss\n",
        "    print(25*'==')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "train_loss : 0.3383790370821953 val_loss : 0.309430827594174\n",
            "train_accuracy : 85.60898716753252 val_accuracy : 86.72951414068166\n",
            "Validation loss decreased (inf --> 0.309431).  Saving model ...\n",
            "==================================================\n",
            "Epoch 2\n",
            "train_loss : 0.2719956298172474 val_loss : 0.2716895123760317\n",
            "train_accuracy : 88.67279428089338 val_accuracy : 88.936082047032\n",
            "Validation loss decreased (0.309431 --> 0.271690).  Saving model ...\n",
            "==================================================\n",
            "Epoch 3\n",
            "train_loss : 0.2426095989677641 val_loss : 0.2735724522119359\n",
            "train_accuracy : 90.24910083921674 val_accuracy : 88.7496115197348\n",
            "==================================================\n",
            "Epoch 4\n",
            "train_loss : 0.215847339572178 val_loss : 0.2700759333418441\n",
            "train_accuracy : 91.49238488521824 val_accuracy : 88.90500362581581\n",
            "Validation loss decreased (0.271690 --> 0.270076).  Saving model ...\n",
            "==================================================\n",
            "Epoch 5\n",
            "train_loss : 0.18897571999165746 val_loss : 0.2697471851396128\n",
            "train_accuracy : 92.82891523466986 val_accuracy : 89.19506889050037\n",
            "Validation loss decreased (0.270076 --> 0.269747).  Saving model ...\n",
            "==================================================\n",
            "Epoch 6\n",
            "train_loss : 0.1564493812703424 val_loss : 0.2864238181262436\n",
            "train_accuracy : 94.03223657919276 val_accuracy : 89.37117994405884\n",
            "==================================================\n",
            "Epoch 7\n",
            "train_loss : 0.1196428662745489 val_loss : 0.3339811526045898\n",
            "train_accuracy : 95.76839394343057 val_accuracy : 88.936082047032\n",
            "==================================================\n",
            "Epoch 8\n",
            "train_loss : 0.0919489223199586 val_loss : 0.3580080739709843\n",
            "train_accuracy : 96.66533457661738 val_accuracy : 88.68745467730238\n",
            "==================================================\n",
            "Epoch 9\n",
            "train_loss : 0.06385061715677795 val_loss : 0.40397392179566033\n",
            "train_accuracy : 97.78873051818303 val_accuracy : 89.27794468041024\n",
            "==================================================\n",
            "Epoch 10\n",
            "train_loss : 0.045659872096601044 val_loss : 0.4745783697948863\n",
            "train_accuracy : 98.35708893921229 val_accuracy : 89.12255257432923\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}