{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_attention.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDtcpXFKMnOX"
      },
      "source": [
        "## Phân loại nội dung độc hại \"Quora Insincere Questions Classification\" - Kaggle\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3sWFzPRLzJY"
      },
      "source": [
        "### **Cài đặt pytorch, kết nối google drive**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9Jwcon4Nk10"
      },
      "source": [
        "Cài đặt pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dxTFbTi0a_S",
        "outputId": "8a4b84d9-d188-4cdf-d1ca-32fb6f0f3dc3"
      },
      "source": [
        "pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.1+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1MB 1.4MB/s eta 0:14:10tcmalloc: large alloc 1147494400 bytes == 0x5560d3c3c000 @  0x7fd66d342615 0x556099f14cdc 0x556099ff452a 0x556099f17afd 0x55609a008fed 0x556099f8b988 0x556099f864ae 0x556099f193ea 0x556099f8b7f0 0x556099f864ae 0x556099f193ea 0x556099f8832a 0x55609a009e36 0x556099f87853 0x55609a009e36 0x556099f87853 0x55609a009e36 0x556099f87853 0x55609a009e36 0x55609a08c3e1 0x556099fec6a9 0x556099f57cc4 0x556099f18559 0x556099f8c4f8 0x556099f1930a 0x556099f873b5 0x556099f867ad 0x556099f193ea 0x556099f873b5 0x556099f1930a 0x556099f873b5\n",
            "\u001b[K     |█████████████████               | 1055.7MB 1.5MB/s eta 0:10:34tcmalloc: large alloc 1434370048 bytes == 0x556118292000 @  0x7fd66d342615 0x556099f14cdc 0x556099ff452a 0x556099f17afd 0x55609a008fed 0x556099f8b988 0x556099f864ae 0x556099f193ea 0x556099f8b7f0 0x556099f864ae 0x556099f193ea 0x556099f8832a 0x55609a009e36 0x556099f87853 0x55609a009e36 0x556099f87853 0x55609a009e36 0x556099f87853 0x55609a009e36 0x55609a08c3e1 0x556099fec6a9 0x556099f57cc4 0x556099f18559 0x556099f8c4f8 0x556099f1930a 0x556099f873b5 0x556099f867ad 0x556099f193ea 0x556099f873b5 0x556099f1930a 0x556099f873b5\n",
            "\u001b[K     |█████████████████████▋          | 1336.2MB 1.3MB/s eta 0:08:35tcmalloc: large alloc 1792966656 bytes == 0x55609d0c4000 @  0x7fd66d342615 0x556099f14cdc 0x556099ff452a 0x556099f17afd 0x55609a008fed 0x556099f8b988 0x556099f864ae 0x556099f193ea 0x556099f8b7f0 0x556099f864ae 0x556099f193ea 0x556099f8832a 0x55609a009e36 0x556099f87853 0x55609a009e36 0x556099f87853 0x55609a009e36 0x556099f87853 0x55609a009e36 0x55609a08c3e1 0x556099fec6a9 0x556099f57cc4 0x556099f18559 0x556099f8c4f8 0x556099f1930a 0x556099f873b5 0x556099f867ad 0x556099f193ea 0x556099f873b5 0x556099f1930a 0x556099f873b5\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1MB 1.3MB/s eta 0:03:44tcmalloc: large alloc 2241208320 bytes == 0x556107eac000 @  0x7fd66d342615 0x556099f14cdc 0x556099ff452a 0x556099f17afd 0x55609a008fed 0x556099f8b988 0x556099f864ae 0x556099f193ea 0x556099f8b7f0 0x556099f864ae 0x556099f193ea 0x556099f8832a 0x55609a009e36 0x556099f87853 0x55609a009e36 0x556099f87853 0x55609a009e36 0x556099f87853 0x55609a009e36 0x55609a08c3e1 0x556099fec6a9 0x556099f57cc4 0x556099f18559 0x556099f8c4f8 0x556099f1930a 0x556099f873b5 0x556099f867ad 0x556099f193ea 0x556099f873b5 0x556099f1930a 0x556099f873b5\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 1.2MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0x55618d80e000 @  0x7fd66d3411e7 0x556099f4af37 0x556099f14cdc 0x556099ff452a 0x556099f17afd 0x55609a008fed 0x556099f8b988 0x556099f864ae 0x556099f193ea 0x556099f8760e 0x556099f864ae 0x556099f193ea 0x556099f8760e 0x556099f864ae 0x556099f193ea 0x556099f8760e 0x556099f864ae 0x556099f193ea 0x556099f8760e 0x556099f864ae 0x556099f193ea 0x556099f8760e 0x556099f1930a 0x556099f8760e 0x556099f864ae 0x556099f193ea 0x556099f8832a 0x556099f864ae 0x556099f193ea 0x556099f8832a 0x556099f864ae\n",
            "tcmalloc: large alloc 2477727744 bytes == 0x556277f2a000 @  0x7fd66d342615 0x556099f14cdc 0x556099ff452a 0x556099f17afd 0x55609a008fed 0x556099f8b988 0x556099f864ae 0x556099f193ea 0x556099f8760e 0x556099f864ae 0x556099f193ea 0x556099f8760e 0x556099f864ae 0x556099f193ea 0x556099f8760e 0x556099f864ae 0x556099f193ea 0x556099f8760e 0x556099f864ae 0x556099f193ea 0x556099f8760e 0x556099f1930a 0x556099f8760e 0x556099f864ae 0x556099f193ea 0x556099f8832a 0x556099f864ae 0x556099f193ea 0x556099f8832a 0x556099f864ae 0x556099f19a81\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 3.8kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6MB 188kB/s \n",
            "\u001b[?25hCollecting torchaudio===0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNL73KrcNnz0"
      },
      "source": [
        "Kết nối drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNwQRFVUNFnM",
        "outputId": "29ae41f9-306c-4957-d364-0da5be4c9879"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v58DWxX2Nu7b"
      },
      "source": [
        "Import thư viện sử dụng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8ZFDK2lNzRn",
        "outputId": "2d988770-ab99-4639-f8d0-4e76a072429a"
      },
      "source": [
        "# standard imports\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "\n",
        "# imports for preprocessing the questions\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# cross validation and metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# progress bars\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSqqh8RROAxe"
      },
      "source": [
        "### **Hiển thị, tiền xử lý dữ liệu**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3FhqE9-IofP"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dHAAvvA_OJ9W",
        "outputId": "ee3c04f0-8973-4fb2-e518-6da1318ac0bf"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/gdrive/MyDrive/LSTM_attention/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/gdrive/MyDrive/LSTM_attention/test.csv\")\n",
        "print('Train data dimension: ', train_df.shape)\n",
        "display(train_df.head())\n",
        "print('Test data dimension: ', test_df.shape)\n",
        "display(test_df.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data dimension:  (1306122, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... target\n",
              "0  00002165364db923c7e6  ...      0\n",
              "1  000032939017120e6e44  ...      0\n",
              "2  0000412ca6e4628ce2cf  ...      0\n",
              "3  000042bf85aa498cd78e  ...      0\n",
              "4  0000455dfa3e01eae3af  ...      0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test data dimension:  (375806, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>Why do so many women become so rude and arroga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>When should I apply for RV college of engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>What is it really like to be a nurse practitio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>Who are entrepreneurs?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>Is education really making good people nowadays?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid                                      question_text\n",
              "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
              "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
              "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
              "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
              "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj8VYxpRJKTo"
      },
      "source": [
        "Ngẫu nhiên bằng pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67wTIVxaI51d"
      },
      "source": [
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKfqeDr1JOZe"
      },
      "source": [
        "Xây dựng hàm tìm kiếm thershold_search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRD6oCM6JkEK"
      },
      "source": [
        "def threshold_search(y_true, y_proba):\n",
        "    best_threshold = 0\n",
        "    best_score = 0\n",
        "    for threshold in tqdm([i * 0.01 for i in range(100)]):\n",
        "        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n",
        "        if score > best_score:\n",
        "            best_threshold = threshold\n",
        "            best_score = score\n",
        "    search_result = {'threshold': best_threshold, 'f1': best_score}\n",
        "    return search_result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U42YVgzZJybB"
      },
      "source": [
        "Hàm sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeTsNb1_JurP"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jls7m6HiJ4Fa"
      },
      "source": [
        "### Tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr-Y1u0NKGaT"
      },
      "source": [
        "Cài đặt các tham số:\n",
        "- embed_size = 300: số chiều vectơ nhúng cho mỗi từ\n",
        "- max_features = 95000: số lượng các từ sử dụng\n",
        "- max_len = 70: số lượng từ lớn nhất trong câu hỏi người dùng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6JRqiv8J26U"
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 95000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 70 # max number of words in a question to use"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD7upy3MK0cA"
      },
      "source": [
        "Làm sạch văn bản, loại bỏ các ký tự thừa, dấu câu,..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJt5LRcaK-Se"
      },
      "source": [
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        x = x.replace(punct, f' {punct} ')\n",
        "    return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw7G-I3_Lpwp"
      },
      "source": [
        "Chuyển dữ liệu về chữ thường, lấp đầy các giá trị thiếu và tokenize các câu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWZ-tXjpLYUl"
      },
      "source": [
        "train_df[\"question_text\"] = train_df[\"question_text\"].str.lower()\n",
        "test_df[\"question_text\"] = test_df[\"question_text\"].str.lower()\n",
        "\n",
        "train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: clean_text(x))\n",
        "test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: clean_text(x))\n",
        "\n",
        "# fill up the missing values\n",
        "x_train = train_df[\"question_text\"].fillna(\"_##_\").values\n",
        "x_test = test_df[\"question_text\"].fillna(\"_##_\").values\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(x_train))\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "# Pad the sentences \n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Get the target values\n",
        "y_train = train_df['target'].values"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NakLBmTuMI25",
        "outputId": "9b5e026d-3995-421b-f977-d6c303a83562"
      },
      "source": [
        "print(train_df[\"question_text\"][0])\n",
        "print(x_train[0])\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "how did quebec nationalists see their province as a nation in the 1960s ? \n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    9   51 6611 7095  162   58 6061   38    4 1147    6    1 8322]\n",
            "(1306122, 70)\n",
            "(375806, 70)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p97KQhYON7PF"
      },
      "source": [
        "- Mã hoá 1306122 mỗi câu hỏi trong x_train thành mỗi câu hỏi có độ dài 70 chứa các chỉ số trong từ điển (đã padding dữ liệu).\n",
        "-  Mã hoá 375806 mỗi câu hỏi trong x_test thành vector có độ dài 70."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOb3vUxVOnVR"
      },
      "source": [
        "### Khởi tạo ma trận nhúng Embeddings Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ3wAaxTPOXo"
      },
      "source": [
        "def load_glove(word_index):\n",
        "    EMBEDDING_FILE = '/content/gdrive/MyDrive/LSTM_attention/glove.840B.300d.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "    \n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = -0.005838499,0.48782197\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    # word_index = tokenizer.word_index\n",
        "    nb_words = min(max_features, len(word_index))\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "            \n",
        "    return embedding_matrix \n",
        "    \n",
        "def load_fasttext(word_index):    \n",
        "    EMBEDDING_FILE = '/content/gdrive/MyDrive/LSTM_attention/wiki-news-300d-1M.vec'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
        "\n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    # word_index = tokenizer.word_index\n",
        "    nb_words = min(max_features, len(word_index))\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "def load_para(word_index):\n",
        "    EMBEDDING_FILE = '/content/gdrive/MyDrive/LSTM_attention/paragram_300_sl999.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
        "\n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = -0.0053247833,0.49346462\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    # word_index = tokenizer.word_index\n",
        "    nb_words = min(max_features, len(word_index))\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "    \n",
        "    return embedding_matrix"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFJPQBwbeSNc",
        "outputId": "90b65b89-2549-4d0f-c9c7-8a2d711d5be5"
      },
      "source": [
        "seed_everything()\n",
        "\n",
        "glove_embeddings = load_glove(tokenizer.word_index)\n",
        "paragram_embeddings = load_para(tokenizer.word_index)\n",
        "\n",
        "embedding_matrix = np.mean([glove_embeddings, paragram_embeddings], axis=0)\n",
        "np.shape(embedding_matrix)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ6o6r1eQmJI"
      },
      "source": [
        "### **Định nghĩa mô hình**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl48wKEXRyDB"
      },
      "source": [
        "Kỹ thuật k-fold cross-validation:\n",
        "- Xáo trộn dữ liệu huấn luyện một cách ngẫu nhiên.\n",
        "- Chia tập huấn luyện k=5 nhóm.\n",
        "- Với mỗi một nhóm: sử dụng 4 nhóm còn lại để huấn luyện mô hình và sử dụng nhóm đó đánh giá hiệu quả mô hình.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISdPGMeGQsgx"
      },
      "source": [
        "splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=10).split(x_train, y_train))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZgzyU46Q_RN",
        "outputId": "fea3c279-db8c-436f-af4b-e8c92c70898a"
      },
      "source": [
        "splits"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([      0,       1,       2, ..., 1306119, 1306120, 1306121]),\n",
              "  array([      9,      10,      12, ..., 1306095, 1306109, 1306112])),\n",
              " (array([      3,       4,       5, ..., 1306119, 1306120, 1306121]),\n",
              "  array([      0,       1,       2, ..., 1306099, 1306100, 1306104])),\n",
              " (array([      0,       1,       2, ..., 1306118, 1306119, 1306121]),\n",
              "  array([      4,       5,       7, ..., 1306108, 1306114, 1306120])),\n",
              " (array([      0,       1,       2, ..., 1306119, 1306120, 1306121]),\n",
              "  array([      6,      13,      21, ..., 1306113, 1306116, 1306118])),\n",
              " (array([      0,       1,       2, ..., 1306116, 1306118, 1306120]),\n",
              "  array([      3,      15,      17, ..., 1306117, 1306119, 1306121]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqwipn69S66F"
      },
      "source": [
        "Cơ chế Attention xây dựng mô hình"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wac4GLkWS6Ks"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.bias = bias\n",
        "        self.feature_dim = feature_dim\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        \n",
        "        weight = torch.zeros(feature_dim, 1)\n",
        "        nn.init.xavier_uniform_(weight)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        \n",
        "        if bias:\n",
        "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
        "        \n",
        "    def forward(self, x, mask=None):\n",
        "        feature_dim = self.feature_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = torch.mm(\n",
        "            x.contiguous().view(-1, feature_dim), \n",
        "            self.weight\n",
        "        ).view(-1, step_dim)\n",
        "        \n",
        "        if self.bias:\n",
        "            eij = eij + self.b\n",
        "            \n",
        "        eij = torch.tanh(eij)\n",
        "        a = torch.exp(eij)\n",
        "        \n",
        "        if mask is not None:\n",
        "            a = a * mask\n",
        "\n",
        "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
        "\n",
        "        weighted_input = x * torch.unsqueeze(a, -1)\n",
        "        return torch.sum(weighted_input, 1)\n",
        "    \n",
        "class SpatialDropout(nn.Dropout2d):\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
        "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
        "        x = x.squeeze(2)  # (N, T, K)\n",
        "        return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SoQ75uNTbaa"
      },
      "source": [
        "Xây dựng mạng Neural Network cho mô hình"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaVLBD_kTfng"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        \n",
        "        hidden_size = 40\n",
        "        \n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        \n",
        "        self.embedding_dropout = SpatialDropout(0.1)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.gru = nn.GRU(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.lstm_attention = Attention(hidden_size * 2, maxlen)\n",
        "        self.gru_attention = Attention(hidden_size * 2, maxlen)\n",
        "        \n",
        "        self.linear = nn.Linear(320, 16)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.out = nn.Linear(16, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_embedding = self.embedding_dropout(h_embedding)\n",
        "        \n",
        "        h_lstm, _ = self.lstm(h_embedding)\n",
        "        h_gru, _ = self.gru(h_lstm)\n",
        "        \n",
        "        h_lstm_atten = self.lstm_attention(h_lstm)\n",
        "        h_gru_atten = self.gru_attention(h_gru)\n",
        "        \n",
        "        # global average pooling\n",
        "        avg_pool = torch.mean(h_gru, 1)\n",
        "        # global max pooling\n",
        "        max_pool, _ = torch.max(h_gru, 1)\n",
        "        \n",
        "        conc = torch.cat((h_lstm_atten, h_gru_atten, avg_pool, max_pool), 1)\n",
        "        conc = self.relu(self.linear(conc))\n",
        "        conc = self.dropout(conc)\n",
        "        out = self.out(conc)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UeRftkxTql8"
      },
      "source": [
        "### **Qúa trình huấn luyện**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fTIG905TwR4"
      },
      "source": [
        "batch_size = 512 # how many samples to process at once\n",
        "n_epochs = 6 # how many times to iterate over all samples"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS3Qs_dPT6yd",
        "outputId": "abd6265a-372b-4418-f9da-a5dfa290951f"
      },
      "source": [
        "# matrix for the out-of-fold predictions\n",
        "train_preds = np.zeros((len(train_df)))\n",
        "# matrix for the predictions on the test set\n",
        "test_preds = np.zeros((len(test_df)))\n",
        "\n",
        "# always call this before training for deterministic results\n",
        "seed_everything()\n",
        "\n",
        "x_test_cuda = torch.tensor(x_test, dtype=torch.long).cuda()\n",
        "test = torch.utils.data.TensorDataset(x_test_cuda)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for i, (train_idx, valid_idx) in enumerate(splits):    \n",
        "    # split data in train / validation according to the KFold indeces\n",
        "    # also, convert them to a torch tensor and store them on the GPU (done with .cuda())\n",
        "    x_train_fold = torch.tensor(x_train[train_idx], dtype=torch.long).cuda()\n",
        "    y_train_fold = torch.tensor(y_train[train_idx, np.newaxis], dtype=torch.float32).cuda()\n",
        "    x_val_fold = torch.tensor(x_train[valid_idx], dtype=torch.long).cuda()\n",
        "    y_val_fold = torch.tensor(y_train[valid_idx, np.newaxis], dtype=torch.float32).cuda()\n",
        "    \n",
        "    model = NeuralNet()\n",
        "    # make sure everything in the model is running on the GPU\n",
        "    model.cuda()\n",
        "\n",
        "    # define binary cross entropy loss\n",
        "    # note that the model returns logit to take advantage of the log-sum-exp trick \n",
        "    # for numerical stability in the loss\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
        "    valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    print(f'Fold {i + 1}')\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        # set train mode of the model. This enables operations which are only applied during training like dropout\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.  \n",
        "        for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
        "            # Forward pass: compute predicted y by passing x to the model.\n",
        "            y_pred = model(x_batch)\n",
        "\n",
        "            # Compute and print loss.\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "            # Before the backward pass, use the optimizer object to zero all of the\n",
        "            # gradients for the Tensors it will update (which are the learnable weights\n",
        "            # of the model)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "\n",
        "            # Calling the step function on an Optimizer makes an update to its parameters\n",
        "            optimizer.step()\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "            \n",
        "        # set evaluation mode of the model. This disabled operations which are only applied during training like dropout\n",
        "        model.eval()\n",
        "        \n",
        "        # predict all the samples in y_val_fold batch per batch\n",
        "        valid_preds_fold = np.zeros((x_val_fold.size(0)))\n",
        "        test_preds_fold = np.zeros((len(test_df)))\n",
        "        \n",
        "        avg_val_loss = 0.\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            y_pred = model(x_batch).detach()\n",
        "            \n",
        "            avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "            valid_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
        "        \n",
        "        elapsed_time = time.time() - start_time \n",
        "        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n",
        "            epoch + 1, n_epochs, avg_loss, avg_val_loss, elapsed_time))\n",
        "        \n",
        "    # predict all samples in the test set batch per batch\n",
        "    for i, (x_batch,) in enumerate(test_loader):\n",
        "        y_pred = model(x_batch).detach()\n",
        "\n",
        "        test_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
        "\n",
        "    train_preds[valid_idx] = valid_preds_fold\n",
        "    test_preds += test_preds_fold / len(splits)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Epoch 1/6 \t loss=0.1258 \t val_loss=0.1081 \t time=61.63s\n",
            "Epoch 2/6 \t loss=0.1077 \t val_loss=0.1034 \t time=62.18s\n",
            "Epoch 3/6 \t loss=0.1029 \t val_loss=0.1006 \t time=62.02s\n",
            "Epoch 4/6 \t loss=0.0994 \t val_loss=0.1015 \t time=62.01s\n",
            "Epoch 5/6 \t loss=0.0964 \t val_loss=0.1000 \t time=62.39s\n",
            "Epoch 6/6 \t loss=0.0940 \t val_loss=0.0985 \t time=62.75s\n",
            "Fold 2\n",
            "Epoch 1/6 \t loss=0.1285 \t val_loss=0.1086 \t time=62.70s\n",
            "Epoch 2/6 \t loss=0.1088 \t val_loss=0.1040 \t time=61.74s\n",
            "Epoch 3/6 \t loss=0.1038 \t val_loss=0.1013 \t time=62.43s\n",
            "Epoch 4/6 \t loss=0.1003 \t val_loss=0.1002 \t time=62.55s\n",
            "Epoch 5/6 \t loss=0.0972 \t val_loss=0.0995 \t time=62.31s\n",
            "Epoch 6/6 \t loss=0.0946 \t val_loss=0.0986 \t time=62.40s\n",
            "Fold 3\n",
            "Epoch 1/6 \t loss=0.1287 \t val_loss=0.1104 \t time=62.43s\n",
            "Epoch 2/6 \t loss=0.1087 \t val_loss=0.1032 \t time=62.38s\n",
            "Epoch 3/6 \t loss=0.1034 \t val_loss=0.1006 \t time=62.70s\n",
            "Epoch 4/6 \t loss=0.0999 \t val_loss=0.0993 \t time=62.28s\n",
            "Epoch 5/6 \t loss=0.0973 \t val_loss=0.0991 \t time=62.34s\n",
            "Epoch 6/6 \t loss=0.0949 \t val_loss=0.0981 \t time=61.91s\n",
            "Fold 4\n",
            "Epoch 1/6 \t loss=0.1283 \t val_loss=0.1078 \t time=62.29s\n",
            "Epoch 2/6 \t loss=0.1082 \t val_loss=0.1026 \t time=62.36s\n",
            "Epoch 3/6 \t loss=0.1031 \t val_loss=0.1009 \t time=62.05s\n",
            "Epoch 4/6 \t loss=0.0999 \t val_loss=0.0994 \t time=62.50s\n",
            "Epoch 5/6 \t loss=0.0968 \t val_loss=0.0986 \t time=62.02s\n",
            "Epoch 6/6 \t loss=0.0945 \t val_loss=0.0978 \t time=62.07s\n",
            "Fold 5\n",
            "Epoch 1/6 \t loss=0.1265 \t val_loss=0.1107 \t time=62.01s\n",
            "Epoch 2/6 \t loss=0.1076 \t val_loss=0.1060 \t time=62.40s\n",
            "Epoch 3/6 \t loss=0.1027 \t val_loss=0.1015 \t time=62.46s\n",
            "Epoch 4/6 \t loss=0.0991 \t val_loss=0.1005 \t time=62.10s\n",
            "Epoch 5/6 \t loss=0.0963 \t val_loss=0.0994 \t time=62.44s\n",
            "Epoch 6/6 \t loss=0.0938 \t val_loss=0.0987 \t time=62.01s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uhlGC33uWBe",
        "outputId": "f101a4f2-38d4-461e-c500-66fb7beffddc"
      },
      "source": [
        "search_result = threshold_search(y_train, train_preds)\n",
        "search_result"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:38<00:00,  2.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.6823369359836746, 'threshold': 0.39}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}